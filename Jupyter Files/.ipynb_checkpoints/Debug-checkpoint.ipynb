{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a97eef6e-a2d2-4570-b970-06a1022900da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from keras.layers import  Dropout\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import datetime\n",
    "from datetime import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7196f772-7007-4418-b69a-c9cf0f9513f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611528/745875612.py:44: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  data.datetime = data.datetime.dt.floor('T')\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Shape of passed values is (1450, 261), indices imply (1450, 259)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[113], line 152\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;66;03m# 将矩阵堆叠成一个大的二维数组\u001b[39;00m\n\u001b[1;32m    150\u001b[0m matrix \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack(matrix)\n\u001b[0;32m--> 152\u001b[0m matrix \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdatetime\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43moffered\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43madd_columns\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m  \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m                      \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq_last\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m                      \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfreq_next\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstart_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mend_time\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiscalYear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiscalMonth\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mficalQuarter\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfiscalWeek\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mDOW\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msort_values(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreset_index(drop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    156\u001b[0m matrix[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhour\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mhour)\n\u001b[1;32m    157\u001b[0m matrix[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mminute\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m matrix\u001b[38;5;241m.\u001b[39mdatetime\u001b[38;5;241m.\u001b[39mmap(\u001b[38;5;28;01mlambda\u001b[39;00m x:x\u001b[38;5;241m.\u001b[39mminute)\n",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/frame.py:827\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    816\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(\n\u001b[1;32m    817\u001b[0m             \u001b[38;5;66;03m# error: Item \"ndarray\" of \"Union[ndarray, Series, Index]\" has no\u001b[39;00m\n\u001b[1;32m    818\u001b[0m             \u001b[38;5;66;03m# attribute \"name\"\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    824\u001b[0m             copy\u001b[38;5;241m=\u001b[39m_copy,\n\u001b[1;32m    825\u001b[0m         )\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 827\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m \u001b[43mndarray_to_mgr\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m            \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m            \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[38;5;66;03m# For data is list-like, or Iterable (will consume into list)\u001b[39;00m\n\u001b[1;32m    837\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(data):\n",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/internals/construction.py:336\u001b[0m, in \u001b[0;36mndarray_to_mgr\u001b[0;34m(values, index, columns, dtype, copy, typ)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;66;03m# _prep_ndarraylike ensures that values.ndim == 2 at this point\u001b[39;00m\n\u001b[1;32m    332\u001b[0m index, columns \u001b[38;5;241m=\u001b[39m _get_axes(\n\u001b[1;32m    333\u001b[0m     values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], values\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], index\u001b[38;5;241m=\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mcolumns\n\u001b[1;32m    334\u001b[0m )\n\u001b[0;32m--> 336\u001b[0m \u001b[43m_check_values_indices_shape_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/internals/construction.py:420\u001b[0m, in \u001b[0;36m_check_values_indices_shape_match\u001b[0;34m(values, index, columns)\u001b[0m\n\u001b[1;32m    418\u001b[0m passed \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m    419\u001b[0m implied \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(index), \u001b[38;5;28mlen\u001b[39m(columns))\n\u001b[0;32m--> 420\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mShape of passed values is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpassed\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, indices imply \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimplied\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Shape of passed values is (1450, 261), indices imply (1450, 259)"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('/workspace/ADP_SBS_Call_Center_Forecasting/Data/MidWest_WFM_Stat_2025_05_16.xlsx')\n",
    "data = pd.read_excel('/workspace/ADP_SBS_Call_Center_Forecasting/Data/CS East WFM STAT 2025_05_14.xlsx')\n",
    "data.columns = ['conversation_start_interval_tmst', 'Time', 'offered', 'actans',\n",
    "               'actabn', 'absActHt', 'absActSa', 'parent', 'child', 'fiscalDate',\n",
    "               'fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']\n",
    "data = data[~data .offered.isna()]\n",
    "path_predict = 'workspace/Midwest_CS_predict_Improved'\n",
    "path_test='workspace/Midwest_CS_test_Improved'\n",
    "data_=data.copy()\n",
    "path='workspace/Midwest_CS_Test_Improved_'\n",
    "holiday_data = pd.read_excel(r'/workspace/ADP_SBS_Call_Center_Forecasting/Data/holiday.xlsx')\n",
    "unique_times_Midwest = [ datetime.time(10, 0),\n",
    "datetime.time(10, 30), datetime.time(11, 0), datetime.time(11, 30),\n",
    "datetime.time(12, 0), datetime.time(12, 30), datetime.time(13, 0),\n",
    "datetime.time(13, 30), datetime.time(14, 0), datetime.time(14, 30),\n",
    "datetime.time(15, 0), datetime.time(15, 30), datetime.time(16, 0),\n",
    "datetime.time(16, 30), datetime.time(17, 0), datetime.time(17, 30),datetime.time(18,0),datetime.time(18,30),datetime.time(19,0),datetime.time(19,30),datetime.time(20,0),datetime.time(20,30)\n",
    "]\n",
    "unique_times= [ datetime.time(7, 0), datetime.time(7, 30), datetime.time(8, 0)\n",
    "                ,datetime.time(8, 30),datetime.time(9, 0), datetime.time(9, 30), datetime.time(10, 0),\n",
    "datetime.time(10, 30), datetime.time(11, 0), datetime.time(11, 30),\n",
    "datetime.time(12, 0), datetime.time(12, 30), datetime.time(13, 0),\n",
    "datetime.time(13, 30), datetime.time(14, 0), datetime.time(14, 30),\n",
    "datetime.time(15, 0), datetime.time(15, 30), datetime.time(16, 0),\n",
    "datetime.time(16, 30), datetime.time(17, 0), datetime.time(17, 30),\n",
    "                 datetime.time(18, 0), datetime.time(18, 30), datetime.time(19, 0)\n",
    "]\n",
    "month_list=['2025-02-15']\n",
    "#change\n",
    "\n",
    "    \n",
    "\n",
    "for month_number in month_list:\n",
    "    data = data[data.conversation_start_interval_tmst<=pd.to_datetime('{} 00:00:00'.format(month_number))]\n",
    "    matrix = []\n",
    "    holiday_data['~is_holiday'] = 0\n",
    "    Holiday_name = ['Christmas Day', 'Columbus Day',\n",
    "           'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "           'Memorial Day', \"New Year's Day\", \"Presidents' Day\", 'Thanksgiving Day',\n",
    "           'Veterans Day']\n",
    "    holiday_data['date'] = holiday_data.Date.dt.date\n",
    "    data['datetime'] = pd.to_datetime(data.conversation_start_interval_tmst)\n",
    "    data['date'] = data.datetime.dt.date\n",
    "    data.datetime = data.datetime.dt.floor('T')\n",
    "    data['datetime'] = data['datetime'].apply(\n",
    "        lambda x: x.ceil('30T') if x.minute == 29 else x\n",
    "    )\n",
    "    data['datetime'] = data['datetime'].apply(\n",
    "        lambda x: x.ceil('H') if x.minute == 59 else x\n",
    "    )\n",
    "    data['time'] = data.datetime.dt.time\n",
    "    data = data.sort_values('datetime').reset_index(drop = True)\n",
    "    data = data.sort_values(by='datetime')\n",
    "    # 获取所有唯一的日期\n",
    "    unique_dates = data['date'].unique()\n",
    "    data = pd.merge(data,holiday_data,on = 'date',how = 'left').fillna(1)\n",
    "    data = data[data['~is_holiday'] == 1]\n",
    "    holiday_datetime = holiday_data.date.to_numpy()\n",
    "    start_time = 35+23 # 58 how many days in advance\n",
    "    end_time = start_time+36 #36 is the train length\n",
    "    add_column = ['actans','actabn','absActHt','absActSa']\n",
    "    add_columns =  [f'actans_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'actabn_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'absActHt_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'absActSa_{i}' for i in range(start_time+1,end_time+1) ]\n",
    "    \n",
    "    # 遍历每个时间点\n",
    "    for time,time1,time2 in zip(unique_times,np.roll(unique_times, shift=-1),np.roll(unique_times, shift=1)):\n",
    "        # 过滤出当前时间点的数据\n",
    "        time_data = data[data['time'] == time].set_index('date')['offered']    \n",
    "        full_dates = pd.date_range(start=unique_dates.min(),end=unique_dates.max()+pd.offsets.BDay(start_time), freq='B') # 仅工作日\n",
    "        full_dates = full_dates.difference(holiday_datetime)\n",
    "        time_data = time_data.groupby(time_data.index).sum()\n",
    "        time_data = time_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data = pd.concat([time_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        add_data = data[data['time'] == time].set_index('date')[add_column]\n",
    "        add_data = add_data.groupby(add_data.index).sum()\n",
    "        add_data = add_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        add_data_ = pd.concat([add_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        time_data1 = data[data['time'] == time1].set_index('date')['offered']    \n",
    "        time_data1 = time_data1.groupby(time_data1.index).sum()\n",
    "        time_data1 = time_data1.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data1 = pd.concat([time_data1.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        time_data2 = data[data['time'] == time2].set_index('date')['offered']    \n",
    "        time_data2 = time_data2.groupby(time_data2.index).sum()\n",
    "        time_data2 = time_data2.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data2 = pd.concat([time_data2.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        # df=time_data.to_frame(name='offer')\n",
    "        # df_last_year = df.copy()\n",
    "        # df_last_year.index = df_last_year.index + pd.DateOffset(years=1)\n",
    "        # df_last_year = df_last_year.rename(columns={'offer': 'offered_last_year'})\n",
    "        # df_last_two_year = df.copy()\n",
    "        # df_last_two_year.index = df_last_two_year.index + pd.DateOffset(years=2)\n",
    "        # df_last_two_year = df_last_two_year.rename(columns={'offer': 'offered_last_two_year'})        \n",
    "        # # Step 3: Join on index\n",
    "        # result = df.join(df_last_year, how='left').join(df_last_two_year,how='left')\n",
    "        # year_data=result[['offered_last_year','offered_last_two_year']]\n",
    "        # 将当前时间点、前半小时和后半小时的数据拼接\n",
    "        combined_data = pd.concat([time_data,add_data_, shifted_data,shifted_data1,shifted_data2,year_data], axis=1)\n",
    "        #combined_data = combined_data.merge(date_column, left_index=True, right_index=True, how='left')\n",
    "        fiscal_start_month = 7  # July\n",
    "\n",
    "        # Fiscal Year\n",
    "        combined_data['fiscalYear'] = combined_data.index.map(\n",
    "            lambda d: f\"FY {d.year + 1}\" if d.month >= fiscal_start_month else f\"FY {d.year}\"\n",
    "        )\n",
    "        \n",
    "        # Fiscal Month Index (1 to 12 from fiscal start)\n",
    "        combined_data['fiscalMonth'] = combined_data.index.map(\n",
    "            lambda d: d.strftime('%B')\n",
    "        )\n",
    "        fiscal_month_index = combined_data.index.month - fiscal_start_month + 1\n",
    "        combined_data['fiscalMonthIndex'] = fiscal_month_index.where(fiscal_month_index > 0, fiscal_month_index + 12)\n",
    "        \n",
    "        # Fiscal Quarter\n",
    "        combined_data['ficalQuarter'] = combined_data['fiscalMonthIndex'].map(lambda m: f\"Q{((m-1)//3)+1}\")\n",
    "        \n",
    "        # Fiscal Week\n",
    "        combined_data['fiscalWeek'] = combined_data.index.isocalendar().week\n",
    "        \n",
    "        # Day of Week\n",
    "        combined_data['DOW'] = combined_data.index.strftime('%A')\n",
    "        combined_data.drop(columns='fiscalMonthIndex', inplace=True)\n",
    "\n",
    "        # 创建日期+时间列\n",
    "        datetime_column = np.array([pd.Timestamp(date) + pd.Timedelta(hours=time.hour, minutes=time.minute) for date in combined_data.index]).reshape(-1, 1)\n",
    "        # 将日期+时间列添加到数据中\n",
    "        combined_data_with_datetime = np.hstack([datetime_column,combined_data.to_numpy()])[-start_time:]\n",
    "        \n",
    "        # 将结果存入矩阵\n",
    "        matrix.append(combined_data_with_datetime)\n",
    "    \n",
    "    max_rows = max(arr.shape[0] for arr in matrix)\n",
    "    \n",
    "    # 将每个时间点的数据填充到最大行数\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i].shape[0] < max_rows:\n",
    "            padding = np.full((max_rows - matrix[i].shape[0], 11), np.nan)  # 用NaN填充（10列数据 + 1列时间）\n",
    "            matrix[i] = np.vstack([matrix[i], padding])\n",
    "            \n",
    "    \n",
    "\n",
    "    # 将矩阵堆叠成一个大的二维数组\n",
    "    matrix = np.vstack(matrix)\n",
    "    \n",
    "    matrix = pd.DataFrame(matrix,columns = ['datetime','offered'] +add_columns +  [f'freq_{i}' for i in range(start_time+1,end_time+1) ]\\\n",
    "                          + [f'freq_last{i}' for i in range(start_time+1,end_time+1) ] + \\\n",
    "                          [f'freq_next{i}' for i in range(start_time+1,end_time+1) ]+ \\\n",
    "                           ['fiscalYear', 'fiscalMonth','ficalQuarter', 'fiscalWeek', 'DOW']).sort_values('datetime').reset_index(drop = True)\n",
    "    matrix['hour'] = matrix.datetime.map(lambda x:x.hour)\n",
    "    matrix['minute'] = matrix.datetime.map(lambda x:x.minute)\n",
    "    matrix = matrix.sort_values('datetime').reset_index(drop = True)\n",
    "    read_data = matrix.iloc[:]\n",
    "    # Quarter: 'Q1' → 1, ..., 'Q4' → 4\n",
    "    quarter_map = {'Q1': 1, 'Q2': 2, 'Q3': 3, 'Q4': 4}\n",
    "    read_data['ficalQuarter'] = read_data['ficalQuarter'].map(quarter_map)\n",
    "    year_map={'FY 2021':1 ,'FY 2022':2,'FY 2023':3,'FY 2024':4, 'FY 2025':5}\n",
    "    read_data['fiscalYear']=read_data['fiscalYear'].map(year_map)\n",
    "    # Month: 'January' → 1, ..., 'December' → 12\n",
    "    month_map = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    read_data['fiscalMonth'] = read_data['fiscalMonth'].map(month_map)\n",
    "    # Day of week: 'Monday' → 0, ..., 'Sunday' → 6\n",
    "    dow_map = {\n",
    "        'Monday': 0, 'Tuesday': 1, 'Wednesday': 2,\n",
    "        'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
    "    }\n",
    "    read_data['DOW'] = read_data['DOW'].map(dow_map)\n",
    "    read_data['fiscalWeek']=read_data['fiscalWeek'].apply(lambda x:pd.to_numeric(x))\n",
    "\n",
    "    # Step 2: Apply cyclical encoding\n",
    "    read_data['ficalQuarter_sin'] = np.sin(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    read_data['ficalQuarter_cos'] = np.cos(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    read_data['fiscalMonth_sin'] = np.sin(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    read_data['fiscalMonth_cos'] = np.cos(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    read_data['fiscalWeek_sin'] = np.sin(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    read_data['fiscalWeek_cos'] = np.cos(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    read_data['DOW_sin'] = np.sin(2 * np.pi * read_data['DOW'] / 7)\n",
    "    read_data['DOW_cos'] = np.cos(2 * np.pi * read_data['DOW'] / 7) \n",
    "    # Hour: 0 to 23\n",
    "    read_data['hour_sin'] = np.sin(2 * np.pi * read_data['hour'] / 24)\n",
    "    read_data['hour_cos'] = np.cos(2 * np.pi * read_data['hour'] / 24)\n",
    "    # Minute: 0 to 59\n",
    "    read_data['minute_sin'] = np.sin(2 * np.pi * read_data['minute'] / 60)\n",
    "    read_data['minute_cos'] = np.cos(2 * np.pi * read_data['minute'] / 60)\n",
    "    # Step 3: Drop original raw categorical time features\n",
    "    read_data.drop(['ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW','hour','minute'], axis=1, inplace=True)\n",
    "    fill_na = read_data.iloc[:,2:].apply(lambda x:pd.to_numeric(x))\n",
    "    #fill_na = fill_na.interpolate(method='linear')\n",
    "    #fill_na.fillna(method='ffill', inplace=True)\n",
    "    fill_na['datetime'] = read_data.datetime\n",
    "    fill_na['date'] = fill_na.datetime.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "75c4404a-42e3-417a-b6f8-115e671c9a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actans_59             3\n",
       "actans_60             3\n",
       "actans_61             3\n",
       "actans_62             3\n",
       "actans_63             3\n",
       "actans_64             3\n",
       "actans_65             3\n",
       "actans_66             3\n",
       "actans_67             3\n",
       "actans_68             3\n",
       "actans_69             3\n",
       "actans_70             3\n",
       "actans_71             3\n",
       "actans_72             3\n",
       "actans_73             3\n",
       "actans_74             3\n",
       "actans_75             3\n",
       "actans_76             3\n",
       "actans_77             3\n",
       "actans_78             3\n",
       "actans_79             2\n",
       "actans_80             2\n",
       "actans_81             2\n",
       "actans_82             2\n",
       "actans_83             2\n",
       "actans_84             2\n",
       "actans_85             2\n",
       "actans_86             2\n",
       "actans_87             2\n",
       "actans_88             2\n",
       "actans_89             2\n",
       "actans_90             2\n",
       "actans_91             2\n",
       "actans_92             2\n",
       "actans_93             2\n",
       "actans_94             2\n",
       "actabn_59             2\n",
       "actabn_60             2\n",
       "actabn_61             2\n",
       "actabn_62             2\n",
       "actabn_63             2\n",
       "actabn_64             2\n",
       "actabn_65             2\n",
       "actabn_66             2\n",
       "actabn_67             2\n",
       "actabn_68             2\n",
       "actabn_69             2\n",
       "actabn_70             2\n",
       "actabn_71             2\n",
       "actabn_72             2\n",
       "actabn_73             2\n",
       "actabn_74             2\n",
       "actabn_75             3\n",
       "actabn_76             3\n",
       "actabn_77             3\n",
       "actabn_78             3\n",
       "actabn_79             3\n",
       "actabn_80             3\n",
       "actabn_81             3\n",
       "actabn_82             3\n",
       "actabn_83             3\n",
       "actabn_84             3\n",
       "actabn_85             3\n",
       "actabn_86             3\n",
       "actabn_87             3\n",
       "actabn_88             3\n",
       "actabn_89             3\n",
       "actabn_90             3\n",
       "actabn_91             3\n",
       "actabn_92             3\n",
       "actabn_93             3\n",
       "actabn_94             3\n",
       "absActHt_59           3\n",
       "absActHt_60           3\n",
       "absActHt_61           3\n",
       "absActHt_62           3\n",
       "absActHt_63           3\n",
       "absActHt_64           3\n",
       "absActHt_65           3\n",
       "absActHt_66           3\n",
       "absActHt_67           3\n",
       "absActHt_68           3\n",
       "absActHt_69           3\n",
       "absActHt_70           3\n",
       "absActHt_71           5\n",
       "absActHt_72           5\n",
       "absActHt_73           5\n",
       "absActHt_74           5\n",
       "absActHt_75           4\n",
       "absActHt_76           4\n",
       "absActHt_77           4\n",
       "absActHt_78           4\n",
       "absActHt_79           4\n",
       "absActHt_80           4\n",
       "absActHt_81           4\n",
       "absActHt_82           4\n",
       "absActHt_83           4\n",
       "absActHt_84           4\n",
       "absActHt_85           4\n",
       "absActHt_86           4\n",
       "absActHt_87           4\n",
       "absActHt_88           4\n",
       "absActHt_89           4\n",
       "absActHt_90           4\n",
       "absActHt_91           4\n",
       "absActHt_92           4\n",
       "absActHt_93           4\n",
       "absActHt_94           4\n",
       "absActSa_59           4\n",
       "absActSa_60           4\n",
       "absActSa_61           4\n",
       "absActSa_62           4\n",
       "absActSa_63           4\n",
       "absActSa_64           4\n",
       "absActSa_65           4\n",
       "absActSa_66           4\n",
       "absActSa_67           5\n",
       "absActSa_68           5\n",
       "absActSa_69           5\n",
       "absActSa_70           5\n",
       "absActSa_71           4\n",
       "absActSa_72           4\n",
       "absActSa_73           4\n",
       "absActSa_74           4\n",
       "absActSa_75           4\n",
       "absActSa_76           4\n",
       "absActSa_77           4\n",
       "absActSa_78           4\n",
       "absActSa_79           4\n",
       "absActSa_80           4\n",
       "absActSa_81           4\n",
       "absActSa_82           4\n",
       "absActSa_83           4\n",
       "absActSa_84           4\n",
       "absActSa_85           4\n",
       "absActSa_86           4\n",
       "absActSa_87           4\n",
       "absActSa_88           4\n",
       "absActSa_89           4\n",
       "absActSa_90           4\n",
       "absActSa_91           3\n",
       "absActSa_92           3\n",
       "absActSa_93           3\n",
       "absActSa_94           3\n",
       "freq_59               3\n",
       "freq_60               3\n",
       "freq_61               3\n",
       "freq_62               3\n",
       "freq_63               3\n",
       "freq_64               2\n",
       "freq_65               2\n",
       "freq_66               2\n",
       "freq_67               2\n",
       "freq_68               2\n",
       "freq_69               2\n",
       "freq_70               2\n",
       "freq_71               2\n",
       "freq_72               3\n",
       "freq_73               3\n",
       "freq_74               3\n",
       "freq_75               3\n",
       "freq_76               3\n",
       "freq_77               3\n",
       "freq_78               3\n",
       "freq_79               3\n",
       "freq_80               5\n",
       "freq_81               4\n",
       "freq_82               4\n",
       "freq_83               4\n",
       "freq_84               4\n",
       "freq_85               4\n",
       "freq_86               4\n",
       "freq_87               4\n",
       "freq_88               5\n",
       "freq_89               4\n",
       "freq_90               4\n",
       "freq_91               4\n",
       "freq_92               4\n",
       "freq_93               4\n",
       "freq_94               3\n",
       "freq_last59           3\n",
       "freq_last60           3\n",
       "freq_last61           3\n",
       "freq_last62           3\n",
       "freq_last63           3\n",
       "freq_last64           2\n",
       "freq_last65           2\n",
       "freq_last66           2\n",
       "freq_last67           2\n",
       "freq_last68           2\n",
       "freq_last69           2\n",
       "freq_last70           2\n",
       "freq_last71           2\n",
       "freq_last72           3\n",
       "freq_last73           3\n",
       "freq_last74           3\n",
       "freq_last75           3\n",
       "freq_last76           3\n",
       "freq_last77           3\n",
       "freq_last78           3\n",
       "freq_last79           3\n",
       "freq_last80           5\n",
       "freq_last81           4\n",
       "freq_last82           4\n",
       "freq_last83           4\n",
       "freq_last84           4\n",
       "freq_last85           4\n",
       "freq_last86           4\n",
       "freq_last87           4\n",
       "freq_last88           5\n",
       "freq_last89           4\n",
       "freq_last90           4\n",
       "freq_last91           4\n",
       "freq_last92           4\n",
       "freq_last93           4\n",
       "freq_last94           3\n",
       "freq_next59           3\n",
       "freq_next60           3\n",
       "freq_next61           3\n",
       "freq_next62           3\n",
       "freq_next63           3\n",
       "freq_next64           2\n",
       "freq_next65           2\n",
       "freq_next66           2\n",
       "freq_next67           2\n",
       "freq_next68           2\n",
       "freq_next69           2\n",
       "freq_next70           2\n",
       "freq_next71           2\n",
       "freq_next72           3\n",
       "freq_next73           3\n",
       "freq_next74           3\n",
       "freq_next75           3\n",
       "freq_next76           3\n",
       "freq_next77           3\n",
       "freq_next78           3\n",
       "freq_next79           3\n",
       "freq_next80           5\n",
       "freq_next81           4\n",
       "freq_next82           4\n",
       "freq_next83           4\n",
       "freq_next84           4\n",
       "freq_next85           4\n",
       "freq_next86           4\n",
       "freq_next87           4\n",
       "freq_next88           5\n",
       "freq_next89           4\n",
       "freq_next90           4\n",
       "freq_next91           4\n",
       "freq_next92           4\n",
       "freq_next93           4\n",
       "freq_next94           3\n",
       "years_data_1        350\n",
       "years_data_2        625\n",
       "fiscalYear            0\n",
       "ficalQuarter_sin      0\n",
       "ficalQuarter_cos      0\n",
       "fiscalMonth_sin       0\n",
       "fiscalMonth_cos       0\n",
       "fiscalWeek_sin        0\n",
       "fiscalWeek_cos        0\n",
       "DOW_sin               0\n",
       "DOW_cos               0\n",
       "hour_sin              0\n",
       "hour_cos              0\n",
       "minute_sin            0\n",
       "minute_cos            0\n",
       "datetime              0\n",
       "date                  0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_na.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d0219d7e-051e-4900-a655-3a7caecd23a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611528/3058256787.py:44: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  data.datetime = data.datetime.dt.floor('T')\n",
      "/tmp/ipykernel_611528/3058256787.py:185: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  fill_na.fillna(method='ffill', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_excel('/workspace/ADP_SBS_Call_Center_Forecasting/Data/MidWest_WFM_Stat_2025_05_16.xlsx')\n",
    "data = pd.read_excel('/workspace/ADP_SBS_Call_Center_Forecasting/Data/CS East WFM STAT 2025_05_14.xlsx')\n",
    "data.columns = ['conversation_start_interval_tmst', 'Time', 'offered', 'actans',\n",
    "               'actabn', 'absActHt', 'absActSa', 'parent', 'child', 'fiscalDate',\n",
    "               'fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']\n",
    "data = data[~data .offered.isna()]\n",
    "path_predict = 'workspace/Midwest_CS_predict_Improved'\n",
    "path_test='workspace/Midwest_CS_test_Improved'\n",
    "data_=data.copy()\n",
    "path='workspace/Midwest_CS_Test_Improved_'\n",
    "holiday_data = pd.read_excel(r'/workspace/ADP_SBS_Call_Center_Forecasting/Data/holiday.xlsx')\n",
    "unique_times_Midwest = [ datetime.time(10, 0),\n",
    "datetime.time(10, 30), datetime.time(11, 0), datetime.time(11, 30),\n",
    "datetime.time(12, 0), datetime.time(12, 30), datetime.time(13, 0),\n",
    "datetime.time(13, 30), datetime.time(14, 0), datetime.time(14, 30),\n",
    "datetime.time(15, 0), datetime.time(15, 30), datetime.time(16, 0),\n",
    "datetime.time(16, 30), datetime.time(17, 0), datetime.time(17, 30),datetime.time(18,0),datetime.time(18,30),datetime.time(19,0),datetime.time(19,30),datetime.time(20,0),datetime.time(20,30)\n",
    "]\n",
    "unique_times= [ datetime.time(7, 0), datetime.time(7, 30), datetime.time(8, 0)\n",
    "                ,datetime.time(8, 30),datetime.time(9, 0), datetime.time(9, 30), datetime.time(10, 0),\n",
    "datetime.time(10, 30), datetime.time(11, 0), datetime.time(11, 30),\n",
    "datetime.time(12, 0), datetime.time(12, 30), datetime.time(13, 0),\n",
    "datetime.time(13, 30), datetime.time(14, 0), datetime.time(14, 30),\n",
    "datetime.time(15, 0), datetime.time(15, 30), datetime.time(16, 0),\n",
    "datetime.time(16, 30), datetime.time(17, 0), datetime.time(17, 30),\n",
    "                 datetime.time(18, 0), datetime.time(18, 30), datetime.time(19, 0)\n",
    "]\n",
    "month_list=['2025-02-15']\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "for month_number in month_list:\n",
    "    data = data[data.conversation_start_interval_tmst<=pd.to_datetime('{} 00:00:00'.format(month_number))]\n",
    "    holiday_data['~is_holiday'] = 0\n",
    "    Holiday_name = ['Christmas Day', 'Columbus Day',\n",
    "           'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "           'Memorial Day', \"New Year's Day\", \"Presidents' Day\", 'Thanksgiving Day',\n",
    "           'Veterans Day']\n",
    "    holiday_data['date'] = holiday_data.Date.dt.date\n",
    "    data['datetime'] = pd.to_datetime(data.conversation_start_interval_tmst)\n",
    "    data['date'] = data.datetime.dt.date\n",
    "    data.datetime = data.datetime.dt.floor('T')\n",
    "    data['datetime'] = data['datetime'].apply(\n",
    "        lambda x: x.ceil('30T') if x.minute == 29 else x\n",
    "    )\n",
    "    data['datetime'] = data['datetime'].apply(\n",
    "        lambda x: x.ceil('H') if x.minute == 59 else x\n",
    "    )\n",
    "    data['time'] = data.datetime.dt.time\n",
    "    data = data.sort_values('datetime').reset_index(drop = True)\n",
    "    data = data.sort_values(by='datetime')\n",
    "    date_column=data[['date',\n",
    "       'fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']]\n",
    "    date_column=date_column.set_index('date')\n",
    "    date_column = date_column[~date_column.index.duplicated(keep='first')]\n",
    "    date_column=date_column.sort_values('date')\n",
    "    # 获取所有唯一的日期\n",
    "    #unique_dates = data['date'].unique()\n",
    "    data = pd.merge(data,holiday_data,on = 'date',how = 'left').fillna(1)\n",
    "    data = data[data['~is_holiday'] == 1]\n",
    "    \n",
    "    holiday_datetime = holiday_data.date.to_numpy()\n",
    "    \n",
    "    start_time = 35+23 # 58 how many days in advance\n",
    "    end_time = start_time+36 #36 is the train length\n",
    "    \n",
    "    \n",
    "    add_column = ['actans','actabn','absActHt','absActSa']\n",
    "    \n",
    "    add_columns =  [f'actans_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'actabn_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'absActHt_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                    [f'absActSa_{i}' for i in range(start_time+1,end_time+1) ]\n",
    "    matrix = []\n",
    "    unique_dates = data['date'].unique()\n",
    "    \n",
    "    # 遍历每个时间点\n",
    "    for time,time1,time2 in zip(unique_times,np.roll(unique_times, shift=-1),np.roll(unique_times, shift=1)):\n",
    "        # 过滤出当前时间点的数据\n",
    "        time_data = data[data['time'] == time].set_index('date')['offered']    \n",
    "        full_dates = pd.date_range(start=unique_dates.min(),end=unique_dates.max()+pd.offsets.BDay(start_time), freq='B') # 仅工作日\n",
    "        full_dates = full_dates.difference(holiday_datetime)\n",
    "        time_data = time_data.groupby(time_data.index).sum()\n",
    "        time_data = time_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data = pd.concat([time_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        add_data = data[data['time'] == time].set_index('date')[add_column]\n",
    "        add_data = add_data.groupby(add_data.index).sum()\n",
    "        add_data = add_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        add_data_ = pd.concat([add_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        time_data1 = data[data['time'] == time1].set_index('date')['offered']    \n",
    "        time_data1 = time_data1.groupby(time_data1.index).sum()\n",
    "        time_data1 = time_data1.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data1 = pd.concat([time_data1.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        time_data2 = data[data['time'] == time2].set_index('date')['offered']    \n",
    "        time_data2 = time_data2.groupby(time_data2.index).sum()\n",
    "        time_data2 = time_data2.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data2 = pd.concat([time_data2.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        df=time_data.to_frame(name='offer')\n",
    "        df_last_year = df.copy()\n",
    "        df_last_year.index = df_last_year.index + pd.DateOffset(years=1)\n",
    "        df_last_year = df_last_year.rename(columns={'offer': 'offered_last_year'})\n",
    "        df_last_two_year = df.copy()\n",
    "        df_last_two_year.index = df_last_two_year.index + pd.DateOffset(years=2)\n",
    "        df_last_two_year = df_last_two_year.rename(columns={'offer': 'offered_last_two_year'})        \n",
    "        # Step 3: Join on index\n",
    "        result = df.join(df_last_year, how='left').join(df_last_two_year,how='left')\n",
    "        year_data=result[['offered_last_year','offered_last_two_year']]\n",
    "        # 将当前时间点、前半小时和后半小时的数据拼接\n",
    "        combined_data = pd.concat([time_data,add_data_, shifted_data,shifted_data1,shifted_data2,year_data], axis=1)\n",
    "        combined_data = combined_data.merge(date_column, left_index=True, right_index=True, how='left')\n",
    "\n",
    "        # 创建日期+时间列\n",
    "        datetime_column = np.array([pd.Timestamp(date) + pd.Timedelta(hours=time.hour, minutes=time.minute) for date in combined_data.index]).reshape(-1, 1)\n",
    "        # 将日期+时间列添加到数据中\n",
    "        combined_data_with_datetime = np.hstack([datetime_column,combined_data.to_numpy()])[-start_time:]\n",
    "        \n",
    "        # 将结果存入矩阵\n",
    "        matrix.append(combined_data_with_datetime)\n",
    "    \n",
    "    max_rows = max(arr.shape[0] for arr in matrix)\n",
    "    \n",
    "    # 将每个时间点的数据填充到最大行数\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i].shape[0] < max_rows:\n",
    "            padding = np.full((max_rows - matrix[i].shape[0], 11), np.nan)  # 用NaN填充（10列数据 + 1列时间）\n",
    "            matrix[i] = np.vstack([matrix[i], padding])\n",
    "    \n",
    "    # 将矩阵堆叠成一个大的二维数组\n",
    "    matrix = np.vstack(matrix)\n",
    "    \n",
    "    matrix = pd.DataFrame(matrix,columns = ['datetime','offered'] +add_columns +  [f'freq_{i}' for i in range(start_time+1,end_time+1) ]\\\n",
    "                          + [f'freq_last{i}' for i in range(start_time+1,end_time+1) ] + \\\n",
    "                          [f'freq_next{i}' for i in range(start_time+1,end_time+1) ]+ \\\n",
    "                           ['years_data_1','years_data_2','fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']).sort_values('datetime').reset_index(drop = True)\n",
    "    matrix['hour'] = matrix.datetime.map(lambda x:x.hour)\n",
    "    matrix['minute'] = matrix.datetime.map(lambda x:x.minute)\n",
    "    matrix = matrix.sort_values('datetime').reset_index(drop = True)\n",
    "    read_data = matrix.iloc[:]\n",
    "    #read_data = read_data[~read_data.offered.isna()].reset_index(drop = True)\n",
    "    # Quarter: 'Q1' → 1, ..., 'Q4' → 4\n",
    "    quarter_map = {'Q1': 1, 'Q2': 2, 'Q3': 3, 'Q4': 4}\n",
    "    read_data['ficalQuarter'] = read_data['ficalQuarter'].map(quarter_map)\n",
    "    year_map={'FY 2021':1 ,'FY 2022':2,'FY 2023':3,'FY 2024':4, 'FY 2025':5}\n",
    "    read_data['fiscalYear']=read_data['fiscalYear'].map(year_map)\n",
    "    # Month: 'January' → 1, ..., 'December' → 12\n",
    "    month_map = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    read_data['fiscalMonth'] = read_data['fiscalMonth'].map(month_map)\n",
    "    # Day of week: 'Monday' → 0, ..., 'Sunday' → 6\n",
    "    dow_map = {\n",
    "        'Monday': 0, 'Tuesday': 1, 'Wednesday': 2,\n",
    "        'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
    "    }\n",
    "    read_data['DOW'] = read_data['DOW'].map(dow_map)\n",
    "    read_data['fiscalWeek']=read_data['fiscalWeek'].apply(lambda x:pd.to_numeric(x))\n",
    "    # Step 2: Apply cyclical encoding\n",
    "    read_data['ficalQuarter_sin'] = np.sin(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    read_data['ficalQuarter_cos'] = np.cos(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    read_data['fiscalMonth_sin'] = np.sin(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    read_data['fiscalMonth_cos'] = np.cos(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    read_data['fiscalWeek_sin'] = np.sin(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    read_data['fiscalWeek_cos'] = np.cos(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    read_data['DOW_sin'] = np.sin(2 * np.pi * read_data['DOW'] / 7)\n",
    "    read_data['DOW_cos'] = np.cos(2 * np.pi * read_data['DOW'] / 7) \n",
    "    # Hour: 0 to 23\n",
    "    read_data['hour_sin'] = np.sin(2 * np.pi * read_data['hour'] / 24)\n",
    "    read_data['hour_cos'] = np.cos(2 * np.pi * read_data['hour'] / 24)\n",
    "    # Minute: 0 to 59\n",
    "    read_data['minute_sin'] = np.sin(2 * np.pi * read_data['minute'] / 60)\n",
    "    read_data['minute_cos'] = np.cos(2 * np.pi * read_data['minute'] / 60)\n",
    "    # Step 3: Drop original raw categorical time features\n",
    "    read_data.drop(['ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW'], axis=1, inplace=True)\n",
    "    fill_na = read_data.iloc[:,2:].apply(lambda x:pd.to_numeric(x))\n",
    "    fill_na = fill_na.interpolate(method='linear')\n",
    "    fill_na.fillna(method='ffill', inplace=True)\n",
    "    fill_na['datetime'] = read_data.datetime\n",
    "    fill_na['date'] = fill_na.datetime.dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "60a9f78d-bbae-4397-9b8a-8aa3d7b32fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "actans_59              0\n",
       "actans_60              0\n",
       "actans_61              0\n",
       "actans_62              0\n",
       "actans_63              0\n",
       "actans_64              0\n",
       "actans_65              0\n",
       "actans_66              0\n",
       "actans_67              0\n",
       "actans_68              0\n",
       "actans_69              0\n",
       "actans_70              0\n",
       "actans_71              0\n",
       "actans_72              0\n",
       "actans_73              0\n",
       "actans_74              0\n",
       "actans_75              0\n",
       "actans_76              0\n",
       "actans_77              0\n",
       "actans_78              0\n",
       "actans_79              0\n",
       "actans_80              0\n",
       "actans_81              0\n",
       "actans_82              0\n",
       "actans_83              0\n",
       "actans_84              0\n",
       "actans_85              0\n",
       "actans_86              0\n",
       "actans_87              0\n",
       "actans_88              0\n",
       "actans_89              0\n",
       "actans_90              0\n",
       "actans_91              0\n",
       "actans_92              0\n",
       "actans_93              0\n",
       "actans_94              0\n",
       "actabn_59              0\n",
       "actabn_60              0\n",
       "actabn_61              0\n",
       "actabn_62              0\n",
       "actabn_63              0\n",
       "actabn_64              0\n",
       "actabn_65              0\n",
       "actabn_66              0\n",
       "actabn_67              0\n",
       "actabn_68              0\n",
       "actabn_69              0\n",
       "actabn_70              0\n",
       "actabn_71              0\n",
       "actabn_72              0\n",
       "actabn_73              0\n",
       "actabn_74              0\n",
       "actabn_75              0\n",
       "actabn_76              0\n",
       "actabn_77              0\n",
       "actabn_78              0\n",
       "actabn_79              0\n",
       "actabn_80              0\n",
       "actabn_81              0\n",
       "actabn_82              0\n",
       "actabn_83              0\n",
       "actabn_84              0\n",
       "actabn_85              0\n",
       "actabn_86              0\n",
       "actabn_87              0\n",
       "actabn_88              0\n",
       "actabn_89              0\n",
       "actabn_90              0\n",
       "actabn_91              0\n",
       "actabn_92              0\n",
       "actabn_93              0\n",
       "actabn_94              0\n",
       "absActHt_59            0\n",
       "absActHt_60            0\n",
       "absActHt_61            0\n",
       "absActHt_62            0\n",
       "absActHt_63            0\n",
       "absActHt_64            0\n",
       "absActHt_65            0\n",
       "absActHt_66            0\n",
       "absActHt_67            0\n",
       "absActHt_68            0\n",
       "absActHt_69            0\n",
       "absActHt_70            0\n",
       "absActHt_71            0\n",
       "absActHt_72            0\n",
       "absActHt_73            0\n",
       "absActHt_74            0\n",
       "absActHt_75            0\n",
       "absActHt_76            0\n",
       "absActHt_77            0\n",
       "absActHt_78            0\n",
       "absActHt_79            0\n",
       "absActHt_80            0\n",
       "absActHt_81            0\n",
       "absActHt_82            0\n",
       "absActHt_83            0\n",
       "absActHt_84            0\n",
       "absActHt_85            0\n",
       "absActHt_86            0\n",
       "absActHt_87            0\n",
       "absActHt_88            0\n",
       "absActHt_89            0\n",
       "absActHt_90            0\n",
       "absActHt_91            0\n",
       "absActHt_92            0\n",
       "absActHt_93            0\n",
       "absActHt_94            0\n",
       "absActSa_59            0\n",
       "absActSa_60            0\n",
       "absActSa_61            0\n",
       "absActSa_62            0\n",
       "absActSa_63            0\n",
       "absActSa_64            0\n",
       "absActSa_65            0\n",
       "absActSa_66            0\n",
       "absActSa_67            0\n",
       "absActSa_68            0\n",
       "absActSa_69            0\n",
       "absActSa_70            0\n",
       "absActSa_71            0\n",
       "absActSa_72            0\n",
       "absActSa_73            0\n",
       "absActSa_74            0\n",
       "absActSa_75            0\n",
       "absActSa_76            0\n",
       "absActSa_77            0\n",
       "absActSa_78            0\n",
       "absActSa_79            0\n",
       "absActSa_80            0\n",
       "absActSa_81            0\n",
       "absActSa_82            0\n",
       "absActSa_83            0\n",
       "absActSa_84            0\n",
       "absActSa_85            0\n",
       "absActSa_86            0\n",
       "absActSa_87            0\n",
       "absActSa_88            0\n",
       "absActSa_89            0\n",
       "absActSa_90            0\n",
       "absActSa_91            0\n",
       "absActSa_92            0\n",
       "absActSa_93            0\n",
       "absActSa_94            0\n",
       "freq_59                0\n",
       "freq_60                0\n",
       "freq_61                0\n",
       "freq_62                0\n",
       "freq_63                0\n",
       "freq_64                0\n",
       "freq_65                0\n",
       "freq_66                0\n",
       "freq_67                0\n",
       "freq_68                0\n",
       "freq_69                0\n",
       "freq_70                0\n",
       "freq_71                0\n",
       "freq_72                0\n",
       "freq_73                0\n",
       "freq_74                0\n",
       "freq_75                0\n",
       "freq_76                0\n",
       "freq_77                0\n",
       "freq_78                0\n",
       "freq_79                0\n",
       "freq_80                0\n",
       "freq_81                0\n",
       "freq_82                0\n",
       "freq_83                0\n",
       "freq_84                0\n",
       "freq_85                0\n",
       "freq_86                0\n",
       "freq_87                0\n",
       "freq_88                0\n",
       "freq_89                0\n",
       "freq_90                0\n",
       "freq_91                0\n",
       "freq_92                0\n",
       "freq_93                0\n",
       "freq_94                0\n",
       "freq_last59            0\n",
       "freq_last60            0\n",
       "freq_last61            0\n",
       "freq_last62            0\n",
       "freq_last63            0\n",
       "freq_last64            0\n",
       "freq_last65            0\n",
       "freq_last66            0\n",
       "freq_last67            0\n",
       "freq_last68            0\n",
       "freq_last69            0\n",
       "freq_last70            0\n",
       "freq_last71            0\n",
       "freq_last72            0\n",
       "freq_last73            0\n",
       "freq_last74            0\n",
       "freq_last75            0\n",
       "freq_last76            0\n",
       "freq_last77            0\n",
       "freq_last78            0\n",
       "freq_last79            0\n",
       "freq_last80            0\n",
       "freq_last81            0\n",
       "freq_last82            0\n",
       "freq_last83            0\n",
       "freq_last84            0\n",
       "freq_last85            0\n",
       "freq_last86            0\n",
       "freq_last87            0\n",
       "freq_last88            0\n",
       "freq_last89            0\n",
       "freq_last90            0\n",
       "freq_last91            0\n",
       "freq_last92            0\n",
       "freq_last93            0\n",
       "freq_last94            0\n",
       "freq_next59            0\n",
       "freq_next60            0\n",
       "freq_next61            0\n",
       "freq_next62            0\n",
       "freq_next63            0\n",
       "freq_next64            0\n",
       "freq_next65            0\n",
       "freq_next66            0\n",
       "freq_next67            0\n",
       "freq_next68            0\n",
       "freq_next69            0\n",
       "freq_next70            0\n",
       "freq_next71            0\n",
       "freq_next72            1\n",
       "freq_next73            0\n",
       "freq_next74            0\n",
       "freq_next75            0\n",
       "freq_next76            0\n",
       "freq_next77            0\n",
       "freq_next78            0\n",
       "freq_next79            0\n",
       "freq_next80            1\n",
       "freq_next81            0\n",
       "freq_next82            0\n",
       "freq_next83            0\n",
       "freq_next84            0\n",
       "freq_next85            0\n",
       "freq_next86            0\n",
       "freq_next87            0\n",
       "freq_next88            0\n",
       "freq_next89            0\n",
       "freq_next90            0\n",
       "freq_next91            0\n",
       "freq_next92            0\n",
       "freq_next93            0\n",
       "freq_next94            0\n",
       "years_data_1          50\n",
       "years_data_2          75\n",
       "fiscalYear          1450\n",
       "hour                   0\n",
       "minute                 0\n",
       "ficalQuarter_sin    1450\n",
       "ficalQuarter_cos    1450\n",
       "fiscalMonth_sin     1450\n",
       "fiscalMonth_cos     1450\n",
       "fiscalWeek_sin      1450\n",
       "fiscalWeek_cos      1450\n",
       "DOW_sin             1450\n",
       "DOW_cos             1450\n",
       "hour_sin               0\n",
       "hour_cos               0\n",
       "minute_sin             0\n",
       "minute_cos             0\n",
       "datetime               0\n",
       "date                   0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_na.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2acaeaa-a478-4335-b19f-5b4e6dda8de9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datetime               0\n",
      "offered             1450\n",
      "actans_59              0\n",
      "actans_60              0\n",
      "actans_61              0\n",
      "actans_62              0\n",
      "actans_63              0\n",
      "actans_64              0\n",
      "actans_65              0\n",
      "actans_66              0\n",
      "actans_67              0\n",
      "actans_68              0\n",
      "actans_69              0\n",
      "actans_70              0\n",
      "actans_71              0\n",
      "actans_72              0\n",
      "actans_73              0\n",
      "actans_74              0\n",
      "actans_75              0\n",
      "actans_76              0\n",
      "actans_77              0\n",
      "actans_78              0\n",
      "actans_79              0\n",
      "actans_80              0\n",
      "actans_81              0\n",
      "actans_82              0\n",
      "actans_83              0\n",
      "actans_84              0\n",
      "actans_85              0\n",
      "actans_86              0\n",
      "actans_87              0\n",
      "actans_88              0\n",
      "actans_89              0\n",
      "actans_90              0\n",
      "actans_91              0\n",
      "actans_92              0\n",
      "actans_93              0\n",
      "actans_94              0\n",
      "actabn_59              0\n",
      "actabn_60              0\n",
      "actabn_61              0\n",
      "actabn_62              0\n",
      "actabn_63              0\n",
      "actabn_64              0\n",
      "actabn_65              0\n",
      "actabn_66              0\n",
      "actabn_67              0\n",
      "actabn_68              0\n",
      "actabn_69              0\n",
      "actabn_70              0\n",
      "actabn_71              0\n",
      "actabn_72              0\n",
      "actabn_73              0\n",
      "actabn_74              0\n",
      "actabn_75              0\n",
      "actabn_76              0\n",
      "actabn_77              0\n",
      "actabn_78              0\n",
      "actabn_79              0\n",
      "actabn_80              0\n",
      "actabn_81              0\n",
      "actabn_82              0\n",
      "actabn_83              0\n",
      "actabn_84              0\n",
      "actabn_85              0\n",
      "actabn_86              0\n",
      "actabn_87              0\n",
      "actabn_88              0\n",
      "actabn_89              0\n",
      "actabn_90              0\n",
      "actabn_91              0\n",
      "actabn_92              0\n",
      "actabn_93              0\n",
      "actabn_94              0\n",
      "absActHt_59            0\n",
      "absActHt_60            0\n",
      "absActHt_61            0\n",
      "absActHt_62            0\n",
      "absActHt_63            0\n",
      "absActHt_64            0\n",
      "absActHt_65            0\n",
      "absActHt_66            0\n",
      "absActHt_67            0\n",
      "absActHt_68            0\n",
      "absActHt_69            0\n",
      "absActHt_70            0\n",
      "absActHt_71            0\n",
      "absActHt_72            0\n",
      "absActHt_73            0\n",
      "absActHt_74            0\n",
      "absActHt_75            0\n",
      "absActHt_76            0\n",
      "absActHt_77            0\n",
      "absActHt_78            0\n",
      "absActHt_79            0\n",
      "absActHt_80            0\n",
      "absActHt_81            0\n",
      "absActHt_82            0\n",
      "absActHt_83            0\n",
      "absActHt_84            0\n",
      "absActHt_85            0\n",
      "absActHt_86            0\n",
      "absActHt_87            0\n",
      "absActHt_88            0\n",
      "absActHt_89            0\n",
      "absActHt_90            0\n",
      "absActHt_91            0\n",
      "absActHt_92            0\n",
      "absActHt_93            0\n",
      "absActHt_94            0\n",
      "absActSa_59            0\n",
      "absActSa_60            0\n",
      "absActSa_61            0\n",
      "absActSa_62            0\n",
      "absActSa_63            0\n",
      "absActSa_64            0\n",
      "absActSa_65            0\n",
      "absActSa_66            0\n",
      "absActSa_67            0\n",
      "absActSa_68            0\n",
      "absActSa_69            0\n",
      "absActSa_70            0\n",
      "absActSa_71            0\n",
      "absActSa_72            0\n",
      "absActSa_73            0\n",
      "absActSa_74            0\n",
      "absActSa_75            0\n",
      "absActSa_76            0\n",
      "absActSa_77            0\n",
      "absActSa_78            0\n",
      "absActSa_79            0\n",
      "absActSa_80            0\n",
      "absActSa_81            0\n",
      "absActSa_82            0\n",
      "absActSa_83            0\n",
      "absActSa_84            0\n",
      "absActSa_85            0\n",
      "absActSa_86            0\n",
      "absActSa_87            0\n",
      "absActSa_88            0\n",
      "absActSa_89            0\n",
      "absActSa_90            0\n",
      "absActSa_91            0\n",
      "absActSa_92            0\n",
      "absActSa_93            0\n",
      "absActSa_94            0\n",
      "freq_59                0\n",
      "freq_60                0\n",
      "freq_61                0\n",
      "freq_62                0\n",
      "freq_63                0\n",
      "freq_64                0\n",
      "freq_65                0\n",
      "freq_66                0\n",
      "freq_67                0\n",
      "freq_68                0\n",
      "freq_69                0\n",
      "freq_70                0\n",
      "freq_71                0\n",
      "freq_72                0\n",
      "freq_73                0\n",
      "freq_74                0\n",
      "freq_75                0\n",
      "freq_76                0\n",
      "freq_77                0\n",
      "freq_78                0\n",
      "freq_79                0\n",
      "freq_80                0\n",
      "freq_81                0\n",
      "freq_82                0\n",
      "freq_83                0\n",
      "freq_84                0\n",
      "freq_85                0\n",
      "freq_86                0\n",
      "freq_87                0\n",
      "freq_88                0\n",
      "freq_89                0\n",
      "freq_90                0\n",
      "freq_91                0\n",
      "freq_92                0\n",
      "freq_93                0\n",
      "freq_94                0\n",
      "freq_last59            0\n",
      "freq_last60            0\n",
      "freq_last61            0\n",
      "freq_last62            0\n",
      "freq_last63            0\n",
      "freq_last64            0\n",
      "freq_last65            0\n",
      "freq_last66            0\n",
      "freq_last67            0\n",
      "freq_last68            0\n",
      "freq_last69            0\n",
      "freq_last70            0\n",
      "freq_last71            0\n",
      "freq_last72            0\n",
      "freq_last73            0\n",
      "freq_last74            0\n",
      "freq_last75            0\n",
      "freq_last76            0\n",
      "freq_last77            0\n",
      "freq_last78            0\n",
      "freq_last79            0\n",
      "freq_last80            0\n",
      "freq_last81            0\n",
      "freq_last82            0\n",
      "freq_last83            0\n",
      "freq_last84            0\n",
      "freq_last85            0\n",
      "freq_last86            0\n",
      "freq_last87            0\n",
      "freq_last88            0\n",
      "freq_last89            0\n",
      "freq_last90            0\n",
      "freq_last91            0\n",
      "freq_last92            0\n",
      "freq_last93            0\n",
      "freq_last94            0\n",
      "freq_next59            0\n",
      "freq_next60            0\n",
      "freq_next61            0\n",
      "freq_next62            0\n",
      "freq_next63            0\n",
      "freq_next64            0\n",
      "freq_next65            0\n",
      "freq_next66            0\n",
      "freq_next67            0\n",
      "freq_next68            0\n",
      "freq_next69            0\n",
      "freq_next70            0\n",
      "freq_next71            0\n",
      "freq_next72            1\n",
      "freq_next73            0\n",
      "freq_next74            0\n",
      "freq_next75            0\n",
      "freq_next76            0\n",
      "freq_next77            0\n",
      "freq_next78            0\n",
      "freq_next79            0\n",
      "freq_next80            1\n",
      "freq_next81            0\n",
      "freq_next82            0\n",
      "freq_next83            0\n",
      "freq_next84            0\n",
      "freq_next85            0\n",
      "freq_next86            0\n",
      "freq_next87            0\n",
      "freq_next88            0\n",
      "freq_next89            0\n",
      "freq_next90            0\n",
      "freq_next91            0\n",
      "freq_next92            0\n",
      "freq_next93            0\n",
      "freq_next94            0\n",
      "years_data_1          50\n",
      "years_data_2          75\n",
      "fiscalYear          1450\n",
      "hour                   0\n",
      "minute                 0\n",
      "ficalQuarter_sin    1450\n",
      "ficalQuarter_cos    1450\n",
      "fiscalMonth_sin     1450\n",
      "fiscalMonth_cos     1450\n",
      "fiscalWeek_sin      1450\n",
      "fiscalWeek_cos      1450\n",
      "DOW_sin             1450\n",
      "DOW_cos             1450\n",
      "hour_sin               0\n",
      "hour_cos               0\n",
      "minute_sin             0\n",
      "minute_cos             0\n",
      "date                   0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "pd.set_option('display.max_rows', None)  # Show all rows (i.e., all columns in .sum())\n",
    "print(fill_na.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b65b8ead-1284-4dd9-bfbc-15a4d7481b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      NaN\n",
       "1      NaN\n",
       "2      NaN\n",
       "3      NaN\n",
       "4      NaN\n",
       "5      NaN\n",
       "6      NaN\n",
       "7      NaN\n",
       "8      NaN\n",
       "9      NaN\n",
       "10     NaN\n",
       "11     NaN\n",
       "12     NaN\n",
       "13     NaN\n",
       "14     NaN\n",
       "15     NaN\n",
       "16     NaN\n",
       "17     NaN\n",
       "18     NaN\n",
       "19     NaN\n",
       "20     NaN\n",
       "21     NaN\n",
       "22     NaN\n",
       "23     NaN\n",
       "24     NaN\n",
       "25     NaN\n",
       "26     NaN\n",
       "27     NaN\n",
       "28     NaN\n",
       "29     NaN\n",
       "30     NaN\n",
       "31     NaN\n",
       "32     NaN\n",
       "33     NaN\n",
       "34     NaN\n",
       "35     NaN\n",
       "36     NaN\n",
       "37     NaN\n",
       "38     NaN\n",
       "39     NaN\n",
       "40     NaN\n",
       "41     NaN\n",
       "42     NaN\n",
       "43     NaN\n",
       "44     NaN\n",
       "45     NaN\n",
       "46     NaN\n",
       "47     NaN\n",
       "48     NaN\n",
       "49     NaN\n",
       "50     NaN\n",
       "51     NaN\n",
       "52     NaN\n",
       "53     NaN\n",
       "54     NaN\n",
       "55     NaN\n",
       "56     NaN\n",
       "57     NaN\n",
       "58     NaN\n",
       "59     NaN\n",
       "60     NaN\n",
       "61     NaN\n",
       "62     NaN\n",
       "63     NaN\n",
       "64     NaN\n",
       "65     NaN\n",
       "66     NaN\n",
       "67     NaN\n",
       "68     NaN\n",
       "69     NaN\n",
       "70     NaN\n",
       "71     NaN\n",
       "72     NaN\n",
       "73     NaN\n",
       "74     NaN\n",
       "75     NaN\n",
       "76     NaN\n",
       "77     NaN\n",
       "78     NaN\n",
       "79     NaN\n",
       "80     NaN\n",
       "81     NaN\n",
       "82     NaN\n",
       "83     NaN\n",
       "84     NaN\n",
       "85     NaN\n",
       "86     NaN\n",
       "87     NaN\n",
       "88     NaN\n",
       "89     NaN\n",
       "90     NaN\n",
       "91     NaN\n",
       "92     NaN\n",
       "93     NaN\n",
       "94     NaN\n",
       "95     NaN\n",
       "96     NaN\n",
       "97     NaN\n",
       "98     NaN\n",
       "99     NaN\n",
       "100    NaN\n",
       "101    NaN\n",
       "102    NaN\n",
       "103    NaN\n",
       "104    NaN\n",
       "105    NaN\n",
       "106    NaN\n",
       "107    NaN\n",
       "108    NaN\n",
       "109    NaN\n",
       "110    NaN\n",
       "111    NaN\n",
       "112    NaN\n",
       "113    NaN\n",
       "114    NaN\n",
       "115    NaN\n",
       "116    NaN\n",
       "117    NaN\n",
       "118    NaN\n",
       "119    NaN\n",
       "120    NaN\n",
       "121    NaN\n",
       "122    NaN\n",
       "123    NaN\n",
       "124    NaN\n",
       "125    NaN\n",
       "126    NaN\n",
       "127    NaN\n",
       "128    NaN\n",
       "129    NaN\n",
       "130    NaN\n",
       "131    NaN\n",
       "132    NaN\n",
       "133    NaN\n",
       "134    NaN\n",
       "135    NaN\n",
       "136    NaN\n",
       "137    NaN\n",
       "138    NaN\n",
       "139    NaN\n",
       "140    NaN\n",
       "141    NaN\n",
       "142    NaN\n",
       "143    NaN\n",
       "144    NaN\n",
       "145    NaN\n",
       "146    NaN\n",
       "147    NaN\n",
       "148    NaN\n",
       "149    NaN\n",
       "150    NaN\n",
       "151    NaN\n",
       "152    NaN\n",
       "153    NaN\n",
       "154    NaN\n",
       "155    NaN\n",
       "156    NaN\n",
       "157    NaN\n",
       "158    NaN\n",
       "159    NaN\n",
       "160    NaN\n",
       "161    NaN\n",
       "162    NaN\n",
       "163    NaN\n",
       "164    NaN\n",
       "165    NaN\n",
       "166    NaN\n",
       "167    NaN\n",
       "168    NaN\n",
       "169    NaN\n",
       "170    NaN\n",
       "171    NaN\n",
       "172    NaN\n",
       "173    NaN\n",
       "174    NaN\n",
       "175    NaN\n",
       "176    NaN\n",
       "177    NaN\n",
       "178    NaN\n",
       "179    NaN\n",
       "180    NaN\n",
       "181    NaN\n",
       "182    NaN\n",
       "183    NaN\n",
       "184    NaN\n",
       "185    NaN\n",
       "186    NaN\n",
       "187    NaN\n",
       "188    NaN\n",
       "189    NaN\n",
       "190    NaN\n",
       "191    NaN\n",
       "192    NaN\n",
       "193    NaN\n",
       "194    NaN\n",
       "195    NaN\n",
       "196    NaN\n",
       "197    NaN\n",
       "198    NaN\n",
       "199    NaN\n",
       "200    NaN\n",
       "201    NaN\n",
       "202    NaN\n",
       "203    NaN\n",
       "204    NaN\n",
       "205    NaN\n",
       "206    NaN\n",
       "207    NaN\n",
       "208    NaN\n",
       "209    NaN\n",
       "210    NaN\n",
       "211    NaN\n",
       "212    NaN\n",
       "213    NaN\n",
       "214    NaN\n",
       "215    NaN\n",
       "216    NaN\n",
       "217    NaN\n",
       "218    NaN\n",
       "219    NaN\n",
       "220    NaN\n",
       "221    NaN\n",
       "222    NaN\n",
       "223    NaN\n",
       "224    NaN\n",
       "225    NaN\n",
       "226    NaN\n",
       "227    NaN\n",
       "228    NaN\n",
       "229    NaN\n",
       "230    NaN\n",
       "231    NaN\n",
       "232    NaN\n",
       "233    NaN\n",
       "234    NaN\n",
       "235    NaN\n",
       "236    NaN\n",
       "237    NaN\n",
       "238    NaN\n",
       "239    NaN\n",
       "240    NaN\n",
       "241    NaN\n",
       "242    NaN\n",
       "243    NaN\n",
       "244    NaN\n",
       "245    NaN\n",
       "246    NaN\n",
       "247    NaN\n",
       "248    NaN\n",
       "249    NaN\n",
       "250    NaN\n",
       "251    NaN\n",
       "252    NaN\n",
       "253    NaN\n",
       "254    NaN\n",
       "255    NaN\n",
       "256    NaN\n",
       "257    NaN\n",
       "258    NaN\n",
       "259    NaN\n",
       "260    NaN\n",
       "261    NaN\n",
       "262    NaN\n",
       "263    NaN\n",
       "264    NaN\n",
       "265    NaN\n",
       "266    NaN\n",
       "267    NaN\n",
       "268    NaN\n",
       "269    NaN\n",
       "270    NaN\n",
       "271    NaN\n",
       "272    NaN\n",
       "273    NaN\n",
       "274    NaN\n",
       "275    NaN\n",
       "276    NaN\n",
       "277    NaN\n",
       "278    NaN\n",
       "279    NaN\n",
       "280    NaN\n",
       "281    NaN\n",
       "282    NaN\n",
       "283    NaN\n",
       "284    NaN\n",
       "285    NaN\n",
       "286    NaN\n",
       "287    NaN\n",
       "288    NaN\n",
       "289    NaN\n",
       "290    NaN\n",
       "291    NaN\n",
       "292    NaN\n",
       "293    NaN\n",
       "294    NaN\n",
       "295    NaN\n",
       "296    NaN\n",
       "297    NaN\n",
       "298    NaN\n",
       "299    NaN\n",
       "300    NaN\n",
       "301    NaN\n",
       "302    NaN\n",
       "303    NaN\n",
       "304    NaN\n",
       "305    NaN\n",
       "306    NaN\n",
       "307    NaN\n",
       "308    NaN\n",
       "309    NaN\n",
       "310    NaN\n",
       "311    NaN\n",
       "312    NaN\n",
       "313    NaN\n",
       "314    NaN\n",
       "315    NaN\n",
       "316    NaN\n",
       "317    NaN\n",
       "318    NaN\n",
       "319    NaN\n",
       "320    NaN\n",
       "321    NaN\n",
       "322    NaN\n",
       "323    NaN\n",
       "324    NaN\n",
       "325    NaN\n",
       "326    NaN\n",
       "327    NaN\n",
       "328    NaN\n",
       "329    NaN\n",
       "330    NaN\n",
       "331    NaN\n",
       "332    NaN\n",
       "333    NaN\n",
       "334    NaN\n",
       "335    NaN\n",
       "336    NaN\n",
       "337    NaN\n",
       "338    NaN\n",
       "339    NaN\n",
       "340    NaN\n",
       "341    NaN\n",
       "342    NaN\n",
       "343    NaN\n",
       "344    NaN\n",
       "345    NaN\n",
       "346    NaN\n",
       "347    NaN\n",
       "348    NaN\n",
       "349    NaN\n",
       "350    NaN\n",
       "351    NaN\n",
       "352    NaN\n",
       "353    NaN\n",
       "354    NaN\n",
       "355    NaN\n",
       "356    NaN\n",
       "357    NaN\n",
       "358    NaN\n",
       "359    NaN\n",
       "360    NaN\n",
       "361    NaN\n",
       "362    NaN\n",
       "363    NaN\n",
       "364    NaN\n",
       "365    NaN\n",
       "366    NaN\n",
       "367    NaN\n",
       "368    NaN\n",
       "369    NaN\n",
       "370    NaN\n",
       "371    NaN\n",
       "372    NaN\n",
       "373    NaN\n",
       "374    NaN\n",
       "375    NaN\n",
       "376    NaN\n",
       "377    NaN\n",
       "378    NaN\n",
       "379    NaN\n",
       "380    NaN\n",
       "381    NaN\n",
       "382    NaN\n",
       "383    NaN\n",
       "384    NaN\n",
       "385    NaN\n",
       "386    NaN\n",
       "387    NaN\n",
       "388    NaN\n",
       "389    NaN\n",
       "390    NaN\n",
       "391    NaN\n",
       "392    NaN\n",
       "393    NaN\n",
       "394    NaN\n",
       "395    NaN\n",
       "396    NaN\n",
       "397    NaN\n",
       "398    NaN\n",
       "399    NaN\n",
       "400    NaN\n",
       "401    NaN\n",
       "402    NaN\n",
       "403    NaN\n",
       "404    NaN\n",
       "405    NaN\n",
       "406    NaN\n",
       "407    NaN\n",
       "408    NaN\n",
       "409    NaN\n",
       "410    NaN\n",
       "411    NaN\n",
       "412    NaN\n",
       "413    NaN\n",
       "414    NaN\n",
       "415    NaN\n",
       "416    NaN\n",
       "417    NaN\n",
       "418    NaN\n",
       "419    NaN\n",
       "420    NaN\n",
       "421    NaN\n",
       "422    NaN\n",
       "423    NaN\n",
       "424    NaN\n",
       "425    NaN\n",
       "426    NaN\n",
       "427    NaN\n",
       "428    NaN\n",
       "429    NaN\n",
       "430    NaN\n",
       "431    NaN\n",
       "432    NaN\n",
       "433    NaN\n",
       "434    NaN\n",
       "435    NaN\n",
       "436    NaN\n",
       "437    NaN\n",
       "438    NaN\n",
       "439    NaN\n",
       "440    NaN\n",
       "441    NaN\n",
       "442    NaN\n",
       "443    NaN\n",
       "444    NaN\n",
       "445    NaN\n",
       "446    NaN\n",
       "447    NaN\n",
       "448    NaN\n",
       "449    NaN\n",
       "450    NaN\n",
       "451    NaN\n",
       "452    NaN\n",
       "453    NaN\n",
       "454    NaN\n",
       "455    NaN\n",
       "456    NaN\n",
       "457    NaN\n",
       "458    NaN\n",
       "459    NaN\n",
       "460    NaN\n",
       "461    NaN\n",
       "462    NaN\n",
       "463    NaN\n",
       "464    NaN\n",
       "465    NaN\n",
       "466    NaN\n",
       "467    NaN\n",
       "468    NaN\n",
       "469    NaN\n",
       "470    NaN\n",
       "471    NaN\n",
       "472    NaN\n",
       "473    NaN\n",
       "474    NaN\n",
       "475    NaN\n",
       "476    NaN\n",
       "477    NaN\n",
       "478    NaN\n",
       "479    NaN\n",
       "480    NaN\n",
       "481    NaN\n",
       "482    NaN\n",
       "483    NaN\n",
       "484    NaN\n",
       "485    NaN\n",
       "486    NaN\n",
       "487    NaN\n",
       "488    NaN\n",
       "489    NaN\n",
       "490    NaN\n",
       "491    NaN\n",
       "492    NaN\n",
       "493    NaN\n",
       "494    NaN\n",
       "495    NaN\n",
       "496    NaN\n",
       "497    NaN\n",
       "498    NaN\n",
       "499    NaN\n",
       "500    NaN\n",
       "501    NaN\n",
       "502    NaN\n",
       "503    NaN\n",
       "504    NaN\n",
       "505    NaN\n",
       "506    NaN\n",
       "507    NaN\n",
       "508    NaN\n",
       "509    NaN\n",
       "510    NaN\n",
       "511    NaN\n",
       "512    NaN\n",
       "513    NaN\n",
       "514    NaN\n",
       "515    NaN\n",
       "516    NaN\n",
       "517    NaN\n",
       "518    NaN\n",
       "519    NaN\n",
       "520    NaN\n",
       "521    NaN\n",
       "522    NaN\n",
       "523    NaN\n",
       "524    NaN\n",
       "525    NaN\n",
       "526    NaN\n",
       "527    NaN\n",
       "528    NaN\n",
       "529    NaN\n",
       "530    NaN\n",
       "531    NaN\n",
       "532    NaN\n",
       "533    NaN\n",
       "534    NaN\n",
       "535    NaN\n",
       "536    NaN\n",
       "537    NaN\n",
       "538    NaN\n",
       "539    NaN\n",
       "540    NaN\n",
       "541    NaN\n",
       "542    NaN\n",
       "543    NaN\n",
       "544    NaN\n",
       "545    NaN\n",
       "546    NaN\n",
       "547    NaN\n",
       "548    NaN\n",
       "549    NaN\n",
       "550    NaN\n",
       "551    NaN\n",
       "552    NaN\n",
       "553    NaN\n",
       "554    NaN\n",
       "555    NaN\n",
       "556    NaN\n",
       "557    NaN\n",
       "558    NaN\n",
       "559    NaN\n",
       "560    NaN\n",
       "561    NaN\n",
       "562    NaN\n",
       "563    NaN\n",
       "564    NaN\n",
       "565    NaN\n",
       "566    NaN\n",
       "567    NaN\n",
       "568    NaN\n",
       "569    NaN\n",
       "570    NaN\n",
       "571    NaN\n",
       "572    NaN\n",
       "573    NaN\n",
       "574    NaN\n",
       "575    NaN\n",
       "576    NaN\n",
       "577    NaN\n",
       "578    NaN\n",
       "579    NaN\n",
       "580    NaN\n",
       "581    NaN\n",
       "582    NaN\n",
       "583    NaN\n",
       "584    NaN\n",
       "585    NaN\n",
       "586    NaN\n",
       "587    NaN\n",
       "588    NaN\n",
       "589    NaN\n",
       "590    NaN\n",
       "591    NaN\n",
       "592    NaN\n",
       "593    NaN\n",
       "594    NaN\n",
       "595    NaN\n",
       "596    NaN\n",
       "597    NaN\n",
       "598    NaN\n",
       "599    NaN\n",
       "600    NaN\n",
       "601    NaN\n",
       "602    NaN\n",
       "603    NaN\n",
       "604    NaN\n",
       "605    NaN\n",
       "606    NaN\n",
       "607    NaN\n",
       "608    NaN\n",
       "609    NaN\n",
       "610    NaN\n",
       "611    NaN\n",
       "612    NaN\n",
       "613    NaN\n",
       "614    NaN\n",
       "615    NaN\n",
       "616    NaN\n",
       "617    NaN\n",
       "618    NaN\n",
       "619    NaN\n",
       "620    NaN\n",
       "621    NaN\n",
       "622    NaN\n",
       "623    NaN\n",
       "624    NaN\n",
       "625    NaN\n",
       "626    NaN\n",
       "627    NaN\n",
       "628    NaN\n",
       "629    NaN\n",
       "630    NaN\n",
       "631    NaN\n",
       "632    NaN\n",
       "633    NaN\n",
       "634    NaN\n",
       "635    NaN\n",
       "636    NaN\n",
       "637    NaN\n",
       "638    NaN\n",
       "639    NaN\n",
       "640    NaN\n",
       "641    NaN\n",
       "642    NaN\n",
       "643    NaN\n",
       "644    NaN\n",
       "645    NaN\n",
       "646    NaN\n",
       "647    NaN\n",
       "648    NaN\n",
       "649    NaN\n",
       "650    NaN\n",
       "651    NaN\n",
       "652    NaN\n",
       "653    NaN\n",
       "654    NaN\n",
       "655    NaN\n",
       "656    NaN\n",
       "657    NaN\n",
       "658    NaN\n",
       "659    NaN\n",
       "660    NaN\n",
       "661    NaN\n",
       "662    NaN\n",
       "663    NaN\n",
       "664    NaN\n",
       "665    NaN\n",
       "666    NaN\n",
       "667    NaN\n",
       "668    NaN\n",
       "669    NaN\n",
       "670    NaN\n",
       "671    NaN\n",
       "672    NaN\n",
       "673    NaN\n",
       "674    NaN\n",
       "675    NaN\n",
       "676    NaN\n",
       "677    NaN\n",
       "678    NaN\n",
       "679    NaN\n",
       "680    NaN\n",
       "681    NaN\n",
       "682    NaN\n",
       "683    NaN\n",
       "684    NaN\n",
       "685    NaN\n",
       "686    NaN\n",
       "687    NaN\n",
       "688    NaN\n",
       "689    NaN\n",
       "690    NaN\n",
       "691    NaN\n",
       "692    NaN\n",
       "693    NaN\n",
       "694    NaN\n",
       "695    NaN\n",
       "696    NaN\n",
       "697    NaN\n",
       "698    NaN\n",
       "699    NaN\n",
       "700    NaN\n",
       "701    NaN\n",
       "702    NaN\n",
       "703    NaN\n",
       "704    NaN\n",
       "705    NaN\n",
       "706    NaN\n",
       "707    NaN\n",
       "708    NaN\n",
       "709    NaN\n",
       "710    NaN\n",
       "711    NaN\n",
       "712    NaN\n",
       "713    NaN\n",
       "714    NaN\n",
       "715    NaN\n",
       "716    NaN\n",
       "717    NaN\n",
       "718    NaN\n",
       "719    NaN\n",
       "720    NaN\n",
       "721    NaN\n",
       "722    NaN\n",
       "723    NaN\n",
       "724    NaN\n",
       "725    NaN\n",
       "726    NaN\n",
       "727    NaN\n",
       "728    NaN\n",
       "729    NaN\n",
       "730    NaN\n",
       "731    NaN\n",
       "732    NaN\n",
       "733    NaN\n",
       "734    NaN\n",
       "735    NaN\n",
       "736    NaN\n",
       "737    NaN\n",
       "738    NaN\n",
       "739    NaN\n",
       "740    NaN\n",
       "741    NaN\n",
       "742    NaN\n",
       "743    NaN\n",
       "744    NaN\n",
       "745    NaN\n",
       "746    NaN\n",
       "747    NaN\n",
       "748    NaN\n",
       "749    NaN\n",
       "750    NaN\n",
       "751    NaN\n",
       "752    NaN\n",
       "753    NaN\n",
       "754    NaN\n",
       "755    NaN\n",
       "756    NaN\n",
       "757    NaN\n",
       "758    NaN\n",
       "759    NaN\n",
       "760    NaN\n",
       "761    NaN\n",
       "762    NaN\n",
       "763    NaN\n",
       "764    NaN\n",
       "765    NaN\n",
       "766    NaN\n",
       "767    NaN\n",
       "768    NaN\n",
       "769    NaN\n",
       "770    NaN\n",
       "771    NaN\n",
       "772    NaN\n",
       "773    NaN\n",
       "774    NaN\n",
       "775    NaN\n",
       "776    NaN\n",
       "777    NaN\n",
       "778    NaN\n",
       "779    NaN\n",
       "780    NaN\n",
       "781    NaN\n",
       "782    NaN\n",
       "783    NaN\n",
       "784    NaN\n",
       "785    NaN\n",
       "786    NaN\n",
       "787    NaN\n",
       "788    NaN\n",
       "789    NaN\n",
       "790    NaN\n",
       "791    NaN\n",
       "792    NaN\n",
       "793    NaN\n",
       "794    NaN\n",
       "795    NaN\n",
       "796    NaN\n",
       "797    NaN\n",
       "798    NaN\n",
       "799    NaN\n",
       "800    NaN\n",
       "801    NaN\n",
       "802    NaN\n",
       "803    NaN\n",
       "804    NaN\n",
       "805    NaN\n",
       "806    NaN\n",
       "807    NaN\n",
       "808    NaN\n",
       "809    NaN\n",
       "810    NaN\n",
       "811    NaN\n",
       "812    NaN\n",
       "813    NaN\n",
       "814    NaN\n",
       "815    NaN\n",
       "816    NaN\n",
       "817    NaN\n",
       "818    NaN\n",
       "819    NaN\n",
       "820    NaN\n",
       "821    NaN\n",
       "822    NaN\n",
       "823    NaN\n",
       "824    NaN\n",
       "825    NaN\n",
       "826    NaN\n",
       "827    NaN\n",
       "828    NaN\n",
       "829    NaN\n",
       "830    NaN\n",
       "831    NaN\n",
       "832    NaN\n",
       "833    NaN\n",
       "834    NaN\n",
       "835    NaN\n",
       "836    NaN\n",
       "837    NaN\n",
       "838    NaN\n",
       "839    NaN\n",
       "840    NaN\n",
       "841    NaN\n",
       "842    NaN\n",
       "843    NaN\n",
       "844    NaN\n",
       "845    NaN\n",
       "846    NaN\n",
       "847    NaN\n",
       "848    NaN\n",
       "849    NaN\n",
       "850    NaN\n",
       "851    NaN\n",
       "852    NaN\n",
       "853    NaN\n",
       "854    NaN\n",
       "855    NaN\n",
       "856    NaN\n",
       "857    NaN\n",
       "858    NaN\n",
       "859    NaN\n",
       "860    NaN\n",
       "861    NaN\n",
       "862    NaN\n",
       "863    NaN\n",
       "864    NaN\n",
       "865    NaN\n",
       "866    NaN\n",
       "867    NaN\n",
       "868    NaN\n",
       "869    NaN\n",
       "870    NaN\n",
       "871    NaN\n",
       "872    NaN\n",
       "873    NaN\n",
       "874    NaN\n",
       "875    NaN\n",
       "876    NaN\n",
       "877    NaN\n",
       "878    NaN\n",
       "879    NaN\n",
       "880    NaN\n",
       "881    NaN\n",
       "882    NaN\n",
       "883    NaN\n",
       "884    NaN\n",
       "885    NaN\n",
       "886    NaN\n",
       "887    NaN\n",
       "888    NaN\n",
       "889    NaN\n",
       "890    NaN\n",
       "891    NaN\n",
       "892    NaN\n",
       "893    NaN\n",
       "894    NaN\n",
       "895    NaN\n",
       "896    NaN\n",
       "897    NaN\n",
       "898    NaN\n",
       "899    NaN\n",
       "900    NaN\n",
       "901    NaN\n",
       "902    NaN\n",
       "903    NaN\n",
       "904    NaN\n",
       "905    NaN\n",
       "906    NaN\n",
       "907    NaN\n",
       "908    NaN\n",
       "909    NaN\n",
       "910    NaN\n",
       "911    NaN\n",
       "912    NaN\n",
       "913    NaN\n",
       "914    NaN\n",
       "915    NaN\n",
       "916    NaN\n",
       "917    NaN\n",
       "918    NaN\n",
       "919    NaN\n",
       "920    NaN\n",
       "921    NaN\n",
       "922    NaN\n",
       "923    NaN\n",
       "924    NaN\n",
       "925    NaN\n",
       "926    NaN\n",
       "927    NaN\n",
       "928    NaN\n",
       "929    NaN\n",
       "930    NaN\n",
       "931    NaN\n",
       "932    NaN\n",
       "933    NaN\n",
       "934    NaN\n",
       "935    NaN\n",
       "936    NaN\n",
       "937    NaN\n",
       "938    NaN\n",
       "939    NaN\n",
       "940    NaN\n",
       "941    NaN\n",
       "942    NaN\n",
       "943    NaN\n",
       "944    NaN\n",
       "945    NaN\n",
       "946    NaN\n",
       "947    NaN\n",
       "948    NaN\n",
       "949    NaN\n",
       "950    NaN\n",
       "951    NaN\n",
       "952    NaN\n",
       "953    NaN\n",
       "954    NaN\n",
       "955    NaN\n",
       "956    NaN\n",
       "957    NaN\n",
       "958    NaN\n",
       "959    NaN\n",
       "960    NaN\n",
       "961    NaN\n",
       "962    NaN\n",
       "963    NaN\n",
       "964    NaN\n",
       "965    NaN\n",
       "966    NaN\n",
       "967    NaN\n",
       "968    NaN\n",
       "969    NaN\n",
       "970    NaN\n",
       "971    NaN\n",
       "972    NaN\n",
       "973    NaN\n",
       "974    NaN\n",
       "975    NaN\n",
       "976    NaN\n",
       "977    NaN\n",
       "978    NaN\n",
       "979    NaN\n",
       "980    NaN\n",
       "981    NaN\n",
       "982    NaN\n",
       "983    NaN\n",
       "984    NaN\n",
       "985    NaN\n",
       "986    NaN\n",
       "987    NaN\n",
       "988    NaN\n",
       "989    NaN\n",
       "990    NaN\n",
       "991    NaN\n",
       "992    NaN\n",
       "993    NaN\n",
       "994    NaN\n",
       "995    NaN\n",
       "996    NaN\n",
       "997    NaN\n",
       "998    NaN\n",
       "999    NaN\n",
       "1000   NaN\n",
       "1001   NaN\n",
       "1002   NaN\n",
       "1003   NaN\n",
       "1004   NaN\n",
       "1005   NaN\n",
       "1006   NaN\n",
       "1007   NaN\n",
       "1008   NaN\n",
       "1009   NaN\n",
       "1010   NaN\n",
       "1011   NaN\n",
       "1012   NaN\n",
       "1013   NaN\n",
       "1014   NaN\n",
       "1015   NaN\n",
       "1016   NaN\n",
       "1017   NaN\n",
       "1018   NaN\n",
       "1019   NaN\n",
       "1020   NaN\n",
       "1021   NaN\n",
       "1022   NaN\n",
       "1023   NaN\n",
       "1024   NaN\n",
       "1025   NaN\n",
       "1026   NaN\n",
       "1027   NaN\n",
       "1028   NaN\n",
       "1029   NaN\n",
       "1030   NaN\n",
       "1031   NaN\n",
       "1032   NaN\n",
       "1033   NaN\n",
       "1034   NaN\n",
       "1035   NaN\n",
       "1036   NaN\n",
       "1037   NaN\n",
       "1038   NaN\n",
       "1039   NaN\n",
       "1040   NaN\n",
       "1041   NaN\n",
       "1042   NaN\n",
       "1043   NaN\n",
       "1044   NaN\n",
       "1045   NaN\n",
       "1046   NaN\n",
       "1047   NaN\n",
       "1048   NaN\n",
       "1049   NaN\n",
       "1050   NaN\n",
       "1051   NaN\n",
       "1052   NaN\n",
       "1053   NaN\n",
       "1054   NaN\n",
       "1055   NaN\n",
       "1056   NaN\n",
       "1057   NaN\n",
       "1058   NaN\n",
       "1059   NaN\n",
       "1060   NaN\n",
       "1061   NaN\n",
       "1062   NaN\n",
       "1063   NaN\n",
       "1064   NaN\n",
       "1065   NaN\n",
       "1066   NaN\n",
       "1067   NaN\n",
       "1068   NaN\n",
       "1069   NaN\n",
       "1070   NaN\n",
       "1071   NaN\n",
       "1072   NaN\n",
       "1073   NaN\n",
       "1074   NaN\n",
       "1075   NaN\n",
       "1076   NaN\n",
       "1077   NaN\n",
       "1078   NaN\n",
       "1079   NaN\n",
       "1080   NaN\n",
       "1081   NaN\n",
       "1082   NaN\n",
       "1083   NaN\n",
       "1084   NaN\n",
       "1085   NaN\n",
       "1086   NaN\n",
       "1087   NaN\n",
       "1088   NaN\n",
       "1089   NaN\n",
       "1090   NaN\n",
       "1091   NaN\n",
       "1092   NaN\n",
       "1093   NaN\n",
       "1094   NaN\n",
       "1095   NaN\n",
       "1096   NaN\n",
       "1097   NaN\n",
       "1098   NaN\n",
       "1099   NaN\n",
       "1100   NaN\n",
       "1101   NaN\n",
       "1102   NaN\n",
       "1103   NaN\n",
       "1104   NaN\n",
       "1105   NaN\n",
       "1106   NaN\n",
       "1107   NaN\n",
       "1108   NaN\n",
       "1109   NaN\n",
       "1110   NaN\n",
       "1111   NaN\n",
       "1112   NaN\n",
       "1113   NaN\n",
       "1114   NaN\n",
       "1115   NaN\n",
       "1116   NaN\n",
       "1117   NaN\n",
       "1118   NaN\n",
       "1119   NaN\n",
       "1120   NaN\n",
       "1121   NaN\n",
       "1122   NaN\n",
       "1123   NaN\n",
       "1124   NaN\n",
       "1125   NaN\n",
       "1126   NaN\n",
       "1127   NaN\n",
       "1128   NaN\n",
       "1129   NaN\n",
       "1130   NaN\n",
       "1131   NaN\n",
       "1132   NaN\n",
       "1133   NaN\n",
       "1134   NaN\n",
       "1135   NaN\n",
       "1136   NaN\n",
       "1137   NaN\n",
       "1138   NaN\n",
       "1139   NaN\n",
       "1140   NaN\n",
       "1141   NaN\n",
       "1142   NaN\n",
       "1143   NaN\n",
       "1144   NaN\n",
       "1145   NaN\n",
       "1146   NaN\n",
       "1147   NaN\n",
       "1148   NaN\n",
       "1149   NaN\n",
       "1150   NaN\n",
       "1151   NaN\n",
       "1152   NaN\n",
       "1153   NaN\n",
       "1154   NaN\n",
       "1155   NaN\n",
       "1156   NaN\n",
       "1157   NaN\n",
       "1158   NaN\n",
       "1159   NaN\n",
       "1160   NaN\n",
       "1161   NaN\n",
       "1162   NaN\n",
       "1163   NaN\n",
       "1164   NaN\n",
       "1165   NaN\n",
       "1166   NaN\n",
       "1167   NaN\n",
       "1168   NaN\n",
       "1169   NaN\n",
       "1170   NaN\n",
       "1171   NaN\n",
       "1172   NaN\n",
       "1173   NaN\n",
       "1174   NaN\n",
       "1175   NaN\n",
       "1176   NaN\n",
       "1177   NaN\n",
       "1178   NaN\n",
       "1179   NaN\n",
       "1180   NaN\n",
       "1181   NaN\n",
       "1182   NaN\n",
       "1183   NaN\n",
       "1184   NaN\n",
       "1185   NaN\n",
       "1186   NaN\n",
       "1187   NaN\n",
       "1188   NaN\n",
       "1189   NaN\n",
       "1190   NaN\n",
       "1191   NaN\n",
       "1192   NaN\n",
       "1193   NaN\n",
       "1194   NaN\n",
       "1195   NaN\n",
       "1196   NaN\n",
       "1197   NaN\n",
       "1198   NaN\n",
       "1199   NaN\n",
       "1200   NaN\n",
       "1201   NaN\n",
       "1202   NaN\n",
       "1203   NaN\n",
       "1204   NaN\n",
       "1205   NaN\n",
       "1206   NaN\n",
       "1207   NaN\n",
       "1208   NaN\n",
       "1209   NaN\n",
       "1210   NaN\n",
       "1211   NaN\n",
       "1212   NaN\n",
       "1213   NaN\n",
       "1214   NaN\n",
       "1215   NaN\n",
       "1216   NaN\n",
       "1217   NaN\n",
       "1218   NaN\n",
       "1219   NaN\n",
       "1220   NaN\n",
       "1221   NaN\n",
       "1222   NaN\n",
       "1223   NaN\n",
       "1224   NaN\n",
       "1225   NaN\n",
       "1226   NaN\n",
       "1227   NaN\n",
       "1228   NaN\n",
       "1229   NaN\n",
       "1230   NaN\n",
       "1231   NaN\n",
       "1232   NaN\n",
       "1233   NaN\n",
       "1234   NaN\n",
       "1235   NaN\n",
       "1236   NaN\n",
       "1237   NaN\n",
       "1238   NaN\n",
       "1239   NaN\n",
       "1240   NaN\n",
       "1241   NaN\n",
       "1242   NaN\n",
       "1243   NaN\n",
       "1244   NaN\n",
       "1245   NaN\n",
       "1246   NaN\n",
       "1247   NaN\n",
       "1248   NaN\n",
       "1249   NaN\n",
       "1250   NaN\n",
       "1251   NaN\n",
       "1252   NaN\n",
       "1253   NaN\n",
       "1254   NaN\n",
       "1255   NaN\n",
       "1256   NaN\n",
       "1257   NaN\n",
       "1258   NaN\n",
       "1259   NaN\n",
       "1260   NaN\n",
       "1261   NaN\n",
       "1262   NaN\n",
       "1263   NaN\n",
       "1264   NaN\n",
       "1265   NaN\n",
       "1266   NaN\n",
       "1267   NaN\n",
       "1268   NaN\n",
       "1269   NaN\n",
       "1270   NaN\n",
       "1271   NaN\n",
       "1272   NaN\n",
       "1273   NaN\n",
       "1274   NaN\n",
       "1275   NaN\n",
       "1276   NaN\n",
       "1277   NaN\n",
       "1278   NaN\n",
       "1279   NaN\n",
       "1280   NaN\n",
       "1281   NaN\n",
       "1282   NaN\n",
       "1283   NaN\n",
       "1284   NaN\n",
       "1285   NaN\n",
       "1286   NaN\n",
       "1287   NaN\n",
       "1288   NaN\n",
       "1289   NaN\n",
       "1290   NaN\n",
       "1291   NaN\n",
       "1292   NaN\n",
       "1293   NaN\n",
       "1294   NaN\n",
       "1295   NaN\n",
       "1296   NaN\n",
       "1297   NaN\n",
       "1298   NaN\n",
       "1299   NaN\n",
       "1300   NaN\n",
       "1301   NaN\n",
       "1302   NaN\n",
       "1303   NaN\n",
       "1304   NaN\n",
       "1305   NaN\n",
       "1306   NaN\n",
       "1307   NaN\n",
       "1308   NaN\n",
       "1309   NaN\n",
       "1310   NaN\n",
       "1311   NaN\n",
       "1312   NaN\n",
       "1313   NaN\n",
       "1314   NaN\n",
       "1315   NaN\n",
       "1316   NaN\n",
       "1317   NaN\n",
       "1318   NaN\n",
       "1319   NaN\n",
       "1320   NaN\n",
       "1321   NaN\n",
       "1322   NaN\n",
       "1323   NaN\n",
       "1324   NaN\n",
       "1325   NaN\n",
       "1326   NaN\n",
       "1327   NaN\n",
       "1328   NaN\n",
       "1329   NaN\n",
       "1330   NaN\n",
       "1331   NaN\n",
       "1332   NaN\n",
       "1333   NaN\n",
       "1334   NaN\n",
       "1335   NaN\n",
       "1336   NaN\n",
       "1337   NaN\n",
       "1338   NaN\n",
       "1339   NaN\n",
       "1340   NaN\n",
       "1341   NaN\n",
       "1342   NaN\n",
       "1343   NaN\n",
       "1344   NaN\n",
       "1345   NaN\n",
       "1346   NaN\n",
       "1347   NaN\n",
       "1348   NaN\n",
       "1349   NaN\n",
       "1350   NaN\n",
       "1351   NaN\n",
       "1352   NaN\n",
       "1353   NaN\n",
       "1354   NaN\n",
       "1355   NaN\n",
       "1356   NaN\n",
       "1357   NaN\n",
       "1358   NaN\n",
       "1359   NaN\n",
       "1360   NaN\n",
       "1361   NaN\n",
       "1362   NaN\n",
       "1363   NaN\n",
       "1364   NaN\n",
       "1365   NaN\n",
       "1366   NaN\n",
       "1367   NaN\n",
       "1368   NaN\n",
       "1369   NaN\n",
       "1370   NaN\n",
       "1371   NaN\n",
       "1372   NaN\n",
       "1373   NaN\n",
       "1374   NaN\n",
       "1375   NaN\n",
       "1376   NaN\n",
       "1377   NaN\n",
       "1378   NaN\n",
       "1379   NaN\n",
       "1380   NaN\n",
       "1381   NaN\n",
       "1382   NaN\n",
       "1383   NaN\n",
       "1384   NaN\n",
       "1385   NaN\n",
       "1386   NaN\n",
       "1387   NaN\n",
       "1388   NaN\n",
       "1389   NaN\n",
       "1390   NaN\n",
       "1391   NaN\n",
       "1392   NaN\n",
       "1393   NaN\n",
       "1394   NaN\n",
       "1395   NaN\n",
       "1396   NaN\n",
       "1397   NaN\n",
       "1398   NaN\n",
       "1399   NaN\n",
       "1400   NaN\n",
       "1401   NaN\n",
       "1402   NaN\n",
       "1403   NaN\n",
       "1404   NaN\n",
       "1405   NaN\n",
       "1406   NaN\n",
       "1407   NaN\n",
       "1408   NaN\n",
       "1409   NaN\n",
       "1410   NaN\n",
       "1411   NaN\n",
       "1412   NaN\n",
       "1413   NaN\n",
       "1414   NaN\n",
       "1415   NaN\n",
       "1416   NaN\n",
       "1417   NaN\n",
       "1418   NaN\n",
       "1419   NaN\n",
       "1420   NaN\n",
       "1421   NaN\n",
       "1422   NaN\n",
       "1423   NaN\n",
       "1424   NaN\n",
       "1425   NaN\n",
       "1426   NaN\n",
       "1427   NaN\n",
       "1428   NaN\n",
       "1429   NaN\n",
       "1430   NaN\n",
       "1431   NaN\n",
       "1432   NaN\n",
       "1433   NaN\n",
       "1434   NaN\n",
       "1435   NaN\n",
       "1436   NaN\n",
       "1437   NaN\n",
       "1438   NaN\n",
       "1439   NaN\n",
       "1440   NaN\n",
       "1441   NaN\n",
       "1442   NaN\n",
       "1443   NaN\n",
       "1444   NaN\n",
       "1445   NaN\n",
       "1446   NaN\n",
       "1447   NaN\n",
       "1448   NaN\n",
       "1449   NaN\n",
       "Name: fiscalYear, dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fill_na['fiscalYear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "93405ebf-5f4e-4fcb-98f2-d4e2f3494287",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_611528/714015081.py:9: FutureWarning: 'T' is deprecated and will be removed in a future version, please use 'min' instead.\n",
      "  data.datetime = data.datetime.dt.floor('T')\n",
      "/tmp/ipykernel_611528/714015081.py:26: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  data = pd.merge(data,holiday_data,on = 'date',how = 'left').fillna(1)\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'~is_holiday'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: '~is_holiday'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 获取所有唯一的日期\u001b[39;00m\n\u001b[1;32m     26\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(data,holiday_data,on \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate\u001b[39m\u001b[38;5;124m'\u001b[39m,how \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mfillna(\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 27\u001b[0m data \u001b[38;5;241m=\u001b[39m data[\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m~is_holiday\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     29\u001b[0m holiday_datetime \u001b[38;5;241m=\u001b[39m holiday_data\u001b[38;5;241m.\u001b[39mdate\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m     31\u001b[0m start_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m35\u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m23\u001b[39m \u001b[38;5;66;03m# 58 how many days in advance\u001b[39;00m\n",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/workspace/lstm/lib/python3.10/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: '~is_holiday'"
     ]
    }
   ],
   "source": [
    "holiday_data['~is_holiday'] = 0\n",
    "Holiday_name = ['Christmas Day', 'Columbus Day',\n",
    "       'Independence Day', 'Labor Day', 'Martin Luther King Jr. Day',\n",
    "       'Memorial Day', \"New Year's Day\", \"Presidents' Day\", 'Thanksgiving Day',\n",
    "       'Veterans Day']\n",
    "holiday_data['date'] = holiday_data.Date.dt.date\n",
    "data['datetime'] = pd.to_datetime(data.conversation_start_interval_tmst)\n",
    "data['date'] = data.datetime.dt.date\n",
    "data.datetime = data.datetime.dt.floor('T')\n",
    "data['datetime'] = data['datetime'].apply(\n",
    "    lambda x: x.ceil('30T') if x.minute == 29 else x\n",
    ")\n",
    "data['datetime'] = data['datetime'].apply(\n",
    "    lambda x: x.ceil('H') if x.minute == 59 else x\n",
    ")\n",
    "data['time'] = data.datetime.dt.time\n",
    "data = data.sort_values('datetime').reset_index(drop = True)\n",
    "data = data.sort_values(by='datetime')\n",
    "date_column=data[['date',\n",
    "   'fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']]\n",
    "date_column=date_column.set_index('date')\n",
    "date_column = date_column[~date_column.index.duplicated(keep='first')]\n",
    "date_column=date_column.sort_values('date')\n",
    "# 获取所有唯一的日期\n",
    "\n",
    "data = pd.merge(data,holiday_data,on = 'date',how = 'left').fillna(1)\n",
    "data = data[data['~is_holiday'] == 1]\n",
    "\n",
    "holiday_datetime = holiday_data.date.to_numpy()\n",
    "\n",
    "start_time = 35+23 # 58 how many days in advance\n",
    "end_time = start_time+36 #36 is the train length\n",
    "\n",
    "\n",
    "add_column = ['actans','actabn','absActHt','absActSa']\n",
    "\n",
    "add_columns =  [f'actans_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                [f'actabn_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                [f'absActHt_{i}' for i in range(start_time+1,end_time+1) ] +\\\n",
    "                [f'absActSa_{i}' for i in range(start_time+1,end_time+1) ]\n",
    "for month_number in month_list:\n",
    "    data = data[data.conversation_start_interval_tmst<=pd.to_datetime('{} 00:00:00'.format(month_number))]\n",
    "    unique_dates = data['date'].unique()\n",
    "    matrix = []\n",
    "    \n",
    "    # 遍历每个时间点\n",
    "    for time,time1,time2 in zip(unique_times,np.roll(unique_times, shift=-1),np.roll(unique_times, shift=1)):\n",
    "        # 过滤出当前时间点的数据\n",
    "        time_data = data[data['time'] == time].set_index('date')['offered']    \n",
    "        full_dates = pd.date_range(start=unique_dates.min(), end=unique_dates.max(), freq='B')  # 仅工作日\n",
    "        full_dates = full_dates.difference(holiday_datetime)\n",
    "        time_data = time_data.groupby(time_data.index).sum()\n",
    "        time_data = time_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data = pd.concat([time_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        add_data = data[data['time'] == time].set_index('date')[add_column]\n",
    "        add_data = add_data.groupby(add_data.index).sum()\n",
    "        add_data = add_data.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        add_data_ = pd.concat([add_data.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        \n",
    "        time_data1 = data[data['time'] == time1].set_index('date')['offered']    \n",
    "        time_data1 = time_data1.groupby(time_data1.index).sum()\n",
    "        time_data1 = time_data1.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data1 = pd.concat([time_data1.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        \n",
    "        time_data2 = data[data['time'] == time2].set_index('date')['offered']    \n",
    "        time_data2 = time_data2.groupby(time_data2.index).sum()\n",
    "        time_data2 = time_data2.reindex(full_dates)  # 重新索引，缺失数据用NaN填充    \n",
    "        shifted_data2 = pd.concat([time_data2.shift(i) for i in range(start_time,end_time)], axis=1)\n",
    "        df=time_data.to_frame(name='offer')\n",
    "        df_last_year = df.copy()\n",
    "        df_last_year.index = df_last_year.index + pd.DateOffset(years=1)\n",
    "        df_last_year = df_last_year.rename(columns={'offer': 'offered_last_year'})\n",
    "        df_last_two_year = df.copy()\n",
    "        df_last_two_year.index = df_last_two_year.index + pd.DateOffset(years=2)\n",
    "        df_last_two_year = df_last_two_year.rename(columns={'offer': 'offered_last_two_year'})        \n",
    "        # Step 3: Join on index\n",
    "        result = df.join(df_last_year, how='left').join(df_last_two_year,how='left')\n",
    "        year_data=result[['offered_last_year','offered_last_two_year']]\n",
    "        #year_data = time_data.shift(251)\n",
    "        # 将当前时间点、前半小时和后半小时的数据拼接\n",
    "        combined_data = pd.concat([time_data,add_data_, shifted_data,shifted_data1,shifted_data2,year_data], axis=1)\n",
    "        combined_data = combined_data.merge(date_column, left_index=True, right_index=True, how='left')\n",
    "\n",
    "        # 创建日期+时间列\n",
    "        #datetime_column = np.array([pd.Timestamp(date) + pd.Timedelta(hours=time.hour, minutes=time.minute) for date in full_dates]).reshape(-1, 1)\n",
    "        datetime_column = np.array([pd.Timestamp(date) + pd.Timedelta(hours=time.hour, minutes=time.minute) for date in combined_data.index]).reshape(-1, 1)\n",
    "        # 将日期+时间列添加到数据中\n",
    "        combined_data_with_datetime = np.hstack([datetime_column,combined_data.to_numpy()])\n",
    "        \n",
    "        # 将结果存入矩阵\n",
    "        matrix.append(combined_data_with_datetime)\n",
    "    \n",
    "    max_rows = max(arr.shape[0] for arr in matrix)\n",
    "    \n",
    "    # 将每个时间点的数据填充到最大行数\n",
    "    for i in range(len(matrix)):\n",
    "        if matrix[i].shape[0] < max_rows:\n",
    "            padding = np.full((max_rows - matrix[i].shape[0], 11), np.nan)  # 用NaN填充（10列数据 + 1列时间）\n",
    "            matrix[i] = np.vstack([matrix[i], padding])\n",
    "    \n",
    "    # 将矩阵堆叠成一个大的二维数组\n",
    "    matrix = np.vstack(matrix)\n",
    "    \n",
    "    matrix = pd.DataFrame(matrix,columns = ['datetime','offered'] +add_columns +  [f'freq_{i}' for i in range(start_time+1,end_time+1) ]\\\n",
    "                          + [f'freq_last{i}' for i in range(start_time+1,end_time+1) ] + \\\n",
    "                          [f'freq_next{i}' for i in range(start_time+1,end_time+1) ]+ \\\n",
    "                           ['years_data_1','years_data_2','fiscalYear', 'ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW']).sort_values('datetime').reset_index(drop = True)\n",
    "    \n",
    "    matrix['hour'] = matrix.datetime.map(lambda x:x.hour)\n",
    "    matrix['minute'] = matrix.datetime.map(lambda x:x.minute)\n",
    "    matrix = matrix.sort_values('datetime').reset_index(drop = True)\n",
    "    \n",
    "    read_data = matrix.iloc[:]\n",
    "    \n",
    "    #read_data = read_data[~read_data.offered.isna()].reset_index(drop = True)\n",
    "    # Quarter: 'Q1' → 1, ..., 'Q4' → 4\n",
    "    quarter_map = {'Q1': 1, 'Q2': 2, 'Q3': 3, 'Q4': 4}\n",
    "    read_data['ficalQuarter'] = read_data['ficalQuarter'].map(quarter_map)\n",
    "    year_map={'FY 2021':1 ,'FY 2022':2,'FY 2023':3,'FY 2024':4, 'FY 2025':5}\n",
    "    read_data['fiscalYear']=read_data['fiscalYear'].map(year_map)\n",
    "    # Month: 'January' → 1, ..., 'December' → 12\n",
    "    month_map = {\n",
    "        'January': 1, 'February': 2, 'March': 3, 'April': 4,\n",
    "        'May': 5, 'June': 6, 'July': 7, 'August': 8,\n",
    "        'September': 9, 'October': 10, 'November': 11, 'December': 12\n",
    "    }\n",
    "    read_data['fiscalMonth'] = read_data['fiscalMonth'].map(month_map)\n",
    "    \n",
    "    # Day of week: 'Monday' → 0, ..., 'Sunday' → 6\n",
    "    dow_map = {\n",
    "        'Monday': 0, 'Tuesday': 1, 'Wednesday': 2,\n",
    "        'Thursday': 3, 'Friday': 4, 'Saturday': 5, 'Sunday': 6\n",
    "    }\n",
    "    read_data['DOW'] = read_data['DOW'].map(dow_map)\n",
    "    read_data['fiscalWeek']=read_data['fiscalWeek'].apply(lambda x:pd.to_numeric(x))\n",
    "    # Step 2: Apply cyclical encoding\n",
    "    \n",
    "    read_data['ficalQuarter_sin'] = np.sin(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    read_data['ficalQuarter_cos'] = np.cos(2 * np.pi * read_data['ficalQuarter'] / 4)\n",
    "    \n",
    "    read_data['fiscalMonth_sin'] = np.sin(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    read_data['fiscalMonth_cos'] = np.cos(2 * np.pi * read_data['fiscalMonth'] / 12)\n",
    "    \n",
    "    read_data['fiscalWeek_sin'] = np.sin(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    read_data['fiscalWeek_cos'] = np.cos(2 * np.pi * read_data['fiscalWeek'] / 52)\n",
    "    \n",
    "    read_data['DOW_sin'] = np.sin(2 * np.pi * read_data['DOW'] / 7)\n",
    "    read_data['DOW_cos'] = np.cos(2 * np.pi * read_data['DOW'] / 7)\n",
    "    # Hour: 0 to 23\n",
    "    read_data['hour_sin'] = np.sin(2 * np.pi * read_data['hour'] / 24)\n",
    "    read_data['hour_cos'] = np.cos(2 * np.pi * read_data['hour'] / 24)\n",
    "    # Minute: 0 to 59\n",
    "    read_data['minute_sin'] = np.sin(2 * np.pi * read_data['minute'] / 60)\n",
    "    read_data['minute_cos'] = np.cos(2 * np.pi * read_data['minute'] / 60)\n",
    "    # Step 3: Drop original raw categorical time features\n",
    "    read_data.drop(['ficalQuarter', 'fiscalMonth', 'fiscalWeek', 'DOW'], axis=1, inplace=True)\n",
    "    fill_na_ = read_data.iloc[:,1:].apply(lambda x:pd.to_numeric(x))\n",
    "\n",
    "    fill_na_ = fill_na.interpolate(method='linear')\n",
    "    \n",
    "    fill_na_['datetime'] = read_data.datetime\n",
    "    fill_na_['date'] = fill_na_.datetime.dt.date\n",
    "    fill_na_ = fill_na_.dropna().reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8503b83c-9db2-4757-a83f-5894f4959b2b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LSTM (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
